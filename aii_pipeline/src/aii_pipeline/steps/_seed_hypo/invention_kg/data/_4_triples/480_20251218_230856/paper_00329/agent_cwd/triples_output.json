{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Fine-tuning (deep learning)",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Core technique adapted and explored for domain-specific LLM optimization across multiple training strategies.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)"
    },
    {
      "name": "Large language model",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "Primary focus area for fine-tuning experiments and optimization strategies.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Large_language_model"
    },
    {
      "name": "Transfer learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Foundational concept underlying the continued pretraining and fine-tuning strategies employed.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transfer_learning"
    },
    {
      "name": "Domain adaptation",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "Central problem being addressed by adapting LLMs for specialized technical domains.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Domain_adaptation"
    },
    {
      "name": "Ensemble learning",
      "entity_type": "method",
      "relation": "proposes",
      "relevance": "Model merging strategy shows that combining multiple fine-tuned models creates emergent capabilities beyond individual models.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Ensemble_learning"
    },
    {
      "name": "Reinforcement learning from human feedback",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Foundation for preference-based optimization approaches (DPO and ORPO) explored in the paper.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback"
    },
    {
      "name": "LLaMA",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "Llama 3.1 8B model used as primary experimental architecture for testing fine-tuning strategies.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Llama_(language_model)"
    },
    {
      "name": "Mistral AI",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "Mistral 7B family of models employed as alternative architecture to test consistency of findings.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Mistral_AI"
    },
    {
      "name": "Text-to-image model",
      "entity_type": "method",
      "relation": "proposes",
      "relevance": "Image generation prompts for biological materials design demonstrate multi-modal application of optimized models.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Text-to-image_model"
    },
    {
      "name": "Generative pre-trained transformer",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Architectural foundation for the LLMs undergoing fine-tuning and optimization in the experiments.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Generative_pre-trained_transformer"
    }
  ]
}
