{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Reinforcement learning",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "relevance": "IRL is a sub-problem within reinforcement learning where the reward function must be inferred from expert behavior."
    },
    {
      "name": "Markov decision process",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Markov_decision_process",
      "relevance": "The paper uses MDPs as the underlying mathematical framework for modeling the decision-making problem."
    },
    {
      "name": "Apprenticeship learning",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Apprenticeship_learning",
      "relevance": "Apprenticeship learning is a key application domain where reward functions are learned by observing an expert's demonstrations."
    },
    {
      "name": "Bayesian inference",
      "relation": "proposes",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Bayesian_inference",
      "relevance": "The paper introduces a novel Bayesian approach to combine prior knowledge with expert evidence to derive a probability distribution over reward functions."
    },
    {
      "name": "Imitation learning",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Imitation_learning",
      "relevance": "The problem of learning from expert demonstrations is central to the inverse reinforcement learning framework presented."
    }
  ]
}
