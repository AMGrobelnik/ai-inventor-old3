{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Reinforcement learning",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "relevance": "The core problem that Decision Transformer reformulates as a sequence modeling task."
    },
    {
      "name": "Transformer (deep learning)",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
      "relevance": "The transformer architecture is the foundation for Decision Transformer's causally masked model."
    },
    {
      "name": "Generative pre-trained transformer",
      "relation": "uses",
      "entity_type": "artifact",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Generative_pre-trained_transformer",
      "relevance": "GPT models provide advances in language modeling that inspire the Decision Transformer approach."
    },
    {
      "name": "BERT (language model)",
      "relation": "uses",
      "entity_type": "artifact",
      "wikipedia_url": "https://en.wikipedia.org/wiki/BERT_(language_model)",
      "relevance": "BERT demonstrates the effectiveness of transformer-based pre-training, informing the design of Decision Transformer."
    },
    {
      "name": "Policy gradient method",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Policy_gradient_method",
      "relevance": "Decision Transformer contrasts with traditional policy gradient approaches by directly outputting actions."
    },
    {
      "name": "Seq2seq",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Seq2seq",
      "relevance": "Sequence-to-sequence modeling provides the foundation for treating RL as conditional sequence generation."
    },
    {
      "name": "Offline learning",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Offline_learning",
      "relevance": "Decision Transformer is evaluated on offline RL benchmarks where it learns from fixed datasets without environment interaction."
    },
    {
      "name": "Atari Games",
      "relation": "uses",
      "entity_type": "data",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Atari_Games",
      "relevance": "Atari games are a standard benchmark used to evaluate Decision Transformer's performance."
    },
    {
      "name": "Products and applications of OpenAI",
      "relation": "uses",
      "entity_type": "tool",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI",
      "relevance": "OpenAI Gym is the environment framework used for evaluating Decision Transformer on reinforcement learning tasks."
    },
    {
      "name": "Deep reinforcement learning",
      "relation": "proposes",
      "entity_type": "artifact",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_reinforcement_learning",
      "relevance": "Decision Transformer is the novel architecture proposed by this paper that combines deep learning with reinforcement learning through sequence modeling."
    }
  ]
}
