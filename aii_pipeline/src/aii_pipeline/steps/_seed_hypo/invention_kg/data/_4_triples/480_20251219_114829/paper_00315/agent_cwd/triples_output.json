{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Speech synthesis",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "The primary task that FastSpeech addresses, generating natural-sounding speech from text",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Speech_synthesis"
    },
    {
      "name": "Neural network (machine learning)",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "FastSpeech is built on neural network architectures for end-to-end TTS",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)"
    },
    {
      "name": "Spectrogram",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The intermediate representation (mel-spectrogram) that FastSpeech generates from text",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Spectrogram"
    },
    {
      "name": "Transformer (deep learning)",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "The core feed-forward network architecture that FastSpeech proposes is based on Transformer",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)"
    },
    {
      "name": "Seq2seq",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "FastSpeech uses an encoder-decoder teacher model based on sequence-to-sequence learning for phoneme duration prediction",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Seq2seq"
    },
    {
      "name": "Phoneme",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "FastSpeech uses phoneme sequences as input and predicts their durations for mel-spectrogram expansion",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Phoneme"
    },
    {
      "name": "Speech corpus",
      "entity_type": "data",
      "relation": "uses",
      "relevance": "The LJSpeech dataset, a speech corpus, is used to evaluate FastSpeech performance",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Speech_corpus"
    },
    {
      "name": "Vocoder",
      "entity_type": "tool",
      "relation": "uses",
      "relevance": "WaveNet, a vocoder, is used in prior TTS work to convert mel-spectrograms to waveforms",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Vocoder"
    },
    {
      "name": "WaveNet",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "The vocoder used in previous end-to-end TTS methods that FastSpeech improves upon",
      "wikipedia_url": "https://en.wikipedia.org/wiki/WaveNet"
    },
    {
      "name": "Autoregressive model",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Previous TTS models like Tacotron 2 use autoregressive generation, which FastSpeech replaces with parallel generation",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Autoregressive_model"
    },
    {
      "name": "Attention (machine learning)",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "FastSpeech extracts attention alignments from the teacher model to guide phoneme duration prediction",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Attention_(machine_learning)"
    },
    {
      "name": "Prosody (linguistics)",
      "entity_type": "concept",
      "relation": "proposes",
      "relevance": "FastSpeech enables controllable prosody generation through voice speed adjustment and smoother prosody control",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Prosody_(linguistics)"
    },
    {
      "name": "Feedforward neural network",
      "entity_type": "method",
      "relation": "proposes",
      "relevance": "FastSpeech's core contribution is a novel feed-forward network architecture for parallel TTS generation",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Feedforward_neural_network"
    }
  ]
}
