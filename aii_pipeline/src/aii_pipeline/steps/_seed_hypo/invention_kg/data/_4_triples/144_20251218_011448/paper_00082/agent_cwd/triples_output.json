{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Prompt engineering",
      "entity_type": "method",
      "relation": "proposes",
      "relevance": "AutoPrompt is an automated approach to prompt engineering for generating effective task-specific prompts without manual effort.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Prompt_engineering"
    },
    {
      "name": "Language model",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "The paper studies what knowledge pretrained language models learn and how to elicit it through automated prompts.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Language_model"
    },
    {
      "name": "Cloze test",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "The paper reformulates tasks as fill-in-the-blanks problems (cloze tests) to gauge knowledge in pretrained language models.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Cloze_test"
    },
    {
      "name": "Gradient descent",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "AutoPrompt uses gradient-guided search to automatically generate effective prompts.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Gradient_descent"
    },
    {
      "name": "BERT (language model)",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "The paper evaluates masked language models like BERT for performing various NLP tasks without fine-tuning.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/BERT_(language_model)"
    },
    {
      "name": "Sentiment analysis",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "The paper demonstrates that MLMs can perform sentiment analysis through AutoPrompt-generated prompts.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Sentiment_analysis"
    },
    {
      "name": "Textual entailment",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "Natural language inference (textual entailment) is evaluated as one of the tasks that MLMs can perform with AutoPrompt.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Textual_entailment"
    },
    {
      "name": "Relationship extraction",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "The paper shows that MLMs can be used as relation extractors more effectively than supervised relation extraction models using AutoPrompt.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Relationship_extraction"
    },
    {
      "name": "Fine-tuning (deep learning)",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "AutoPrompt provides a parameter-free alternative to fine-tuning, a traditional approach for adapting language models to specific tasks.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)"
    },
    {
      "name": "Transfer learning",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The paper leverages transfer learning principles by eliciting knowledge from pretrained language models without additional parameters.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transfer_learning"
    },
    {
      "name": "Language model benchmark",
      "entity_type": "data",
      "relation": "uses",
      "relevance": "The paper evaluates AutoPrompt-generated prompts on benchmark datasets to demonstrate the effectiveness of the approach.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Language_model_benchmark"
    }
  ]
}
