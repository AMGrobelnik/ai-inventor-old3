{
  "paper_type": "survey",
  "triples": [
    {
      "name": "Human-computer interaction",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The core field that multimodal interaction extends by enabling multi-channel communication between users and systems.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Human-computer_interaction"
    },
    {
      "name": "Speech recognition",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "A key input modality in multimodal systems enabling voice-based user interaction.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Speech_recognition"
    },
    {
      "name": "Gesture recognition",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "A critical technique for detecting and interpreting hand and body movements as input modalities in multimodal interfaces.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Gesture_recognition"
    },
    {
      "name": "Touchscreen",
      "entity_type": "tool",
      "relation": "uses",
      "relevance": "A fundamental touch input technology enabling direct tactile interaction in multimodal systems.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Touchscreen"
    },
    {
      "name": "Eye tracking",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "A technique for measuring gaze direction and eye movement as a natural input modality for multimodal interaction.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Eye_tracking"
    },
    {
      "name": "Machine learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Statistical algorithms essential for processing and understanding diverse input modalities in multimodal systems.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Machine_learning"
    },
    {
      "name": "Sensor",
      "entity_type": "tool",
      "relation": "uses",
      "relevance": "Devices that detect user inputs and environmental changes, forming the hardware foundation for multimodal data capture.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Sensor"
    },
    {
      "name": "Multimodal interaction",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The core framework enabling users to interact with systems through multiple communication channels simultaneously.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Multimodal_interaction"
    },
    {
      "name": "Sensor fusion",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "A technique for combining data from multiple sensors to reduce uncertainty and improve decision-level integration in multimodal systems.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Sensor_fusion"
    },
    {
      "name": "Virtual assistant",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "A key application domain where multimodal interaction enables natural and intuitive user engagement through voice, gesture, and other modalities.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Virtual_assistant"
    },
    {
      "name": "Intelligent environment",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "A significant application of multimodal systems where embedded sensors and interfaces create interactive, context-aware physical spaces.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Intelligent_environment"
    },
    {
      "name": "Assistive technology",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "A crucial application area where multimodal interaction enhances accessibility for people with disabilities through alternative input/output modalities.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Assistive_technology"
    }
  ]
}
