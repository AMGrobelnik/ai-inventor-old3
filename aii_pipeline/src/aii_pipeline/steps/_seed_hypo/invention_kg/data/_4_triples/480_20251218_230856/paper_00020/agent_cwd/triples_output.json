{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Reinforcement Learning",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "relevance": "The core problem domain that the paper addresses by making reward functions visible to learning agents."
    },
    {
      "name": "Finite-state Machine",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Finite-state_machine",
      "relevance": "Theoretical foundation for reward machines, providing the basis for their computational structure."
    },
    {
      "name": "Policy Learning",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Policy_learning",
      "relevance": "The primary objective that agents learn through exploiting reward machine structure."
    },
    {
      "name": "Q-learning",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Q-learning",
      "relevance": "Example off-policy RL algorithm that can be enhanced with reward machine structure."
    },
    {
      "name": "Linear Temporal Logic",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Linear_temporal_logic",
      "relevance": "Formalism used to express temporally extended reward properties in reward machines."
    },
    {
      "name": "Regular Language",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Regular_language",
      "relevance": "Defines the expressive power of reward machines as finite state machines recognizing regular languages."
    },
    {
      "name": "State-action-reward-state-action",
      "relation": "proposes",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/State-Action-Reward-State-Action",
      "relevance": "Reward machines extend this RL learning model to explicitly expose reward function structure through finite state specifications."
    },
    {
      "name": "Reward Shaping",
      "relation": "proposes",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reward_hacking",
      "relevance": "Automated methodology for modifying rewards based on reward machine structure to improve learning efficiency."
    },
    {
      "name": "Task Decomposition",
      "relation": "proposes",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Hierarchical_task_network",
      "relevance": "Methodology to break complex learning problems into simpler subtasks using reward machine structure."
    },
    {
      "name": "Counterfactual Thinking",
      "relation": "proposes",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Counterfactual_thinking",
      "relevance": "Reasoning approach used with off-policy learning to improve sample efficiency through reward structure."
    }
  ]
}
