{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Speech synthesis",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Speech_synthesis",
      "relevance": "FastSpeech addresses the core task of converting text to natural speech through neural network-based synthesis."
    },
    {
      "name": "Neural network (machine learning)",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
      "relevance": "FastSpeech is built on neural network architecture to perform end-to-end text-to-speech synthesis."
    },
    {
      "name": "Deep learning speech synthesis",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_learning_speech_synthesis",
      "relevance": "The paper advances the field of deep learning-based speech synthesis with a faster parallel generation approach."
    },
    {
      "name": "Spectrogram",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Spectrogram",
      "relevance": "Mel-spectrograms are the intermediate representation generated by FastSpeech before converting to waveforms."
    },
    {
      "name": "WaveNet",
      "relation": "uses",
      "entity_type": "artifact",
      "wikipedia_url": "https://en.wikipedia.org/wiki/WaveNet",
      "relevance": "FastSpeech uses vocoders like WaveNet to convert mel-spectrograms to raw audio waveforms."
    },
    {
      "name": "Transformer (deep learning)",
      "relation": "proposes",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
      "relevance": "FastSpeech proposes a feed-forward Transformer-based architecture as a novel approach to parallel mel-spectrogram generation."
    },
    {
      "name": "Attention (machine learning)",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Attention_(machine_learning)",
      "relevance": "Attention alignments from the teacher model are extracted to train the phoneme duration prediction module."
    },
    {
      "name": "Autoregressive model",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Autoregressive_model",
      "relevance": "FastSpeech addresses limitations of autoregressive TTS models like Tacotron 2 by proposing a non-autoregressive parallel approach."
    },
    {
      "name": "List of datasets for machine-learning research",
      "relation": "uses",
      "entity_type": "data",
      "wikipedia_url": "https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research",
      "relevance": "The LJSpeech dataset used for FastSpeech evaluation is included in curated lists of machine learning datasets."
    }
  ]
}
