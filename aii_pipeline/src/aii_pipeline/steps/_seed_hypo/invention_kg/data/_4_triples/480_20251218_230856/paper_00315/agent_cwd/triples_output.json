{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Speech synthesis",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Speech_synthesis",
      "relevance": "FastSpeech addresses the core task of synthesizing speech from text, improving upon neural network-based text-to-speech approaches."
    },
    {
      "name": "Transformer (deep learning architecture)",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)",
      "relevance": "FastSpeech is built on a feed-forward Transformer network as its core architecture for parallel mel-spectrogram generation."
    },
    {
      "name": "Attention (machine learning)",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Attention_(machine_learning)",
      "relevance": "The paper extracts attention alignments from the teacher model to determine phoneme durations for the length regulator."
    },
    {
      "name": "WaveNet",
      "relation": "uses",
      "entity_type": "artifact",
      "wikipedia_url": "https://en.wikipedia.org/wiki/WaveNet",
      "relevance": "FastSpeech uses WaveNet as a vocoder component to synthesize speech waveforms from mel-spectrograms."
    },
    {
      "name": "Autoregressive model",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Autoregressive_model",
      "relevance": "The paper improves upon autoregressive TTS models by proposing a parallel, non-autoregressive architecture that eliminates sequential generation bottlenecks."
    },
    {
      "name": "Spectrogram",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Spectrogram",
      "relevance": "Mel-spectrograms are the intermediate representation that FastSpeech generates before converting to speech waveforms."
    },
    {
      "name": "Autoencoder",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Autoencoder",
      "relevance": "FastSpeech leverages encoder-decoder architecture from its teacher model (similar to Tacotron) to extract duration alignments for duration prediction."
    },
    {
      "name": "Deep learning speech synthesis",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_learning_speech_synthesis",
      "relevance": "FastSpeech advances the field of neural network-based speech synthesis with improved speed, robustness, and controllability."
    },
    {
      "name": "FastSpeech",
      "relation": "proposes",
      "entity_type": "artifact",
      "wikipedia_url": "https://en.wikipedia.org/wiki/FastSpeech",
      "relevance": "The main contribution of the paper: a novel feed-forward Transformer-based model for fast, robust, and controllable text-to-speech synthesis."
    },
    {
      "name": "LJSpeech dataset",
      "relation": "uses",
      "entity_type": "data",
      "wikipedia_url": "https://en.wikipedia.org/wiki/LJSpeech",
      "relevance": "FastSpeech is evaluated on the LJSpeech dataset, a benchmark dataset for TTS evaluation."
    }
  ]
}
