{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Speech synthesis",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "Text-to-speech synthesis is the main task being addressed by the paper.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Speech_synthesis"
    },
    {
      "name": "Language model",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "The paper treats TTS as a language modeling task, using neural codec language models as the core approach.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Language_model"
    },
    {
      "name": "Audio codec",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "The paper leverages an existing neural audio codec model to derive discrete codes for training.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Audio_codec"
    },
    {
      "name": "Autoencoder",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Neural audio codecs are typically implemented as autoencoders that compress and decompress audio data.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Autoencoder"
    },
    {
      "name": "Deep learning speech synthesis",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The paper builds on deep learning approaches to speech synthesis with neural networks.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_learning_speech_synthesis"
    },
    {
      "name": "In-context learning",
      "entity_type": "concept",
      "relation": "proposes",
      "relevance": "The paper demonstrates that Vall-E exhibits emergent in-context learning capabilities for speaker adaptation.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/In-context_learning_(natural_language_processing)"
    },
    {
      "name": "Speaker recognition",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "The paper evaluates speaker similarity, which is related to speaker recognition and voice authentication.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Speaker_recognition"
    },
    {
      "name": "Emotion recognition",
      "entity_type": "task",
      "relation": "proposes",
      "relevance": "The paper demonstrates that Vall-E preserves emotion from the acoustic prompt during synthesis.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Emotion_recognition"
    },
    {
      "name": "Voice conversion",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "The paper's approach of synthesizing personalized speech relates to voice conversion techniques.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Retrieval-based_Voice_Conversion"
    },
    {
      "name": "WaveNet",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "WaveNet is a foundational deep learning approach to speech synthesis and audio generation.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/WaveNet"
    }
  ]
}
