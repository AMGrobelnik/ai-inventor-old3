{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Generative pre-trained transformer",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "DialoGPT builds on the generative pre-training approach used by transformer models for natural language tasks.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Generative_pre-trained_transformer"
    },
    {
      "name": "Dialogue system",
      "entity_type": "task",
      "relation": "proposes",
      "relevance": "The paper proposes DialoGPT as a method for building conversational dialogue systems that can generate appropriate responses.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Dialogue_system"
    },
    {
      "name": "Natural language generation",
      "entity_type": "task",
      "relation": "proposes",
      "relevance": "DialoGPT is designed specifically for natural language generation in conversational contexts.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Natural_language_generation"
    },
    {
      "name": "Transformer (deep learning)",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "The transformer architecture is the underlying neural network architecture that powers the DialoGPT model.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)"
    },
    {
      "name": "Language model",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "DialoGPT is fundamentally a language model that uses generative pre-training to learn conversational patterns.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Language_modeling"
    }
  ]
}
