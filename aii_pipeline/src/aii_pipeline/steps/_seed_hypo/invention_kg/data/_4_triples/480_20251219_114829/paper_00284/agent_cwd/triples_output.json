{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "BERT (language model)",
      "relation": "uses",
      "entity_type": "artifact",
      "wikipedia_url": "https://en.wikipedia.org/wiki/BERT_(language_model)",
      "relevance": "The paper builds upon BERT as a pre-trained transformer model to enable multimodal adaptation."
    },
    {
      "name": "XLNet",
      "relation": "uses",
      "entity_type": "artifact",
      "wikipedia_url": "https://en.wikipedia.org/wiki/XLNet",
      "relevance": "The paper adapts XLNet with the MAG framework to handle multimodal inputs for sentiment analysis."
    },
    {
      "name": "Transformer (deep learning)",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
      "relevance": "Transformers are the foundational architecture that BERT and XLNet are built upon."
    },
    {
      "name": "Natural language processing",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Natural_language_processing",
      "relevance": "The paper addresses multimodal sentiment analysis, a task within the NLP domain."
    },
    {
      "name": "Sentiment analysis",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Sentiment_analysis",
      "relevance": "The paper focuses on improving multimodal sentiment analysis performance on benchmark datasets."
    },
    {
      "name": "Multimodal sentiment analysis",
      "relation": "proposes",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Multimodal_sentiment_analysis",
      "relevance": "The paper advances multimodal sentiment analysis by enabling transformers to process visual and acoustic modalities."
    },
    {
      "name": "Multimodal learning",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Multimodal_learning",
      "relevance": "The paper integrates vision and acoustic modalities with language for improved sentiment understanding."
    },
    {
      "name": "Fine-tuning (deep learning)",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)",
      "relevance": "The paper applies fine-tuning to pre-trained BERT and XLNet models on multimodal datasets."
    },
    {
      "name": "Attention (machine learning)",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Attention_(machine_learning)",
      "relevance": "Attention mechanisms are core to the transformer architecture that the paper extends with multimodal capabilities."
    }
  ]
}
