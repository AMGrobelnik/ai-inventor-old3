{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "GPT-3",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "GPT-3 is used as the backbone of the algorithm for generating synthetic medical dialogue data.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/GPT-3"
    },
    {
      "name": "Automatic summarization",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "Medical dialogue summarization is the core task that the paper addresses.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Automatic_summarization"
    },
    {
      "name": "Few-shot learning",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Low-shot learning is a key technique used to scale 210 human examples to match the performance of 6400 examples.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Few-shot_learning"
    },
    {
      "name": "Ensemble learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "An ensemble method is employed to aggregate predictions and improve the quality of synthetic data generation.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Ensemble_learning"
    },
    {
      "name": "Synthetic data",
      "entity_type": "data",
      "relation": "proposes",
      "relevance": "The paper proposes an algorithm for creating synthetic training data for medical dialogue summarization with explicit focus on medical relevance.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Synthetic_data"
    }
  ]
}
