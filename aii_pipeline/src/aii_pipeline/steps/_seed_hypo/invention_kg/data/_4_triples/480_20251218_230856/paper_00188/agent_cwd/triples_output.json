{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Reinforcement learning",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Foundation for inverse reinforcement learning, which is the inverse problem of the standard RL framework.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning"
    },
    {
      "name": "Markov decision process",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The formal framework used to model the system dynamics in IRL problems.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Markov_decision_process"
    },
    {
      "name": "Bayesian inference",
      "entity_type": "method",
      "relation": "proposes",
      "relevance": "The paper proposes a Bayesian approach to combine prior knowledge with expert evidence to derive probability distributions over reward functions.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Bayesian_inference"
    },
    {
      "name": "Apprenticeship learning",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "One of the key applications of IRL addressed in the paper for learning policies from expert demonstrations.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Apprenticeship_learning"
    }
  ]
}
