{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Diffusion model",
      "entity_type": "method",
      "relation": "proposes",
      "relevance": "The paper extends diffusion models from generative modeling to robot visuomotor policy learning.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Diffusion_model",
      "wikidata": {
        "id": "Q114617315",
        "label": "diffusion model",
        "description": "deep learning algorithm",
        "aliases": [
          "diffusion probabilistic model",
          "text-to-image diffusion model",
          "score-based generative model",
          "diffusion transformer",
          "DiT"
        ],
        "claims": {
          "subclass_of": [
            "Q1806885",
            "Q85810444"
          ],
          "P1269": {
            "id": "Q197536",
            "label": "deep learning"
          },
          "use": [
            {
              "id": "Q108033749",
              "label": "image denoising"
            },
            "Q1628157",
            {
              "id": "Q440296",
              "label": "image scaling"
            },
            "Q113403137"
          ],
          "P973": "https://medium.com/@threehappyer/understanding-dit-diffusion-transformer-in-one-article-2f7c330ad0ea",
          "described_by_source": [
            {
              "id": "Q130456647",
              "label": "Latte: Latent Diffusion Transformer for Video Generation"
            },
            {
              "id": "Q123176998",
              "label": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"
            }
          ]
        }
      }
    },
    {
      "name": "Langevin dynamics",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "The paper uses stochastic Langevin dynamics steps during policy inference for iterative optimization.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Langevin_dynamics",
      "wikidata": {
        "id": "Q6485978",
        "label": "Langevin dynamics",
        "description": "scientific theory",
        "aliases": [],
        "claims": {
          "P2534": "M\\ddot{X} = - \\nabla U(X) - \\gamma \\dot{X} + \\sqrt{2 \\gamma k_B T} R(t)\\,",
          "P50": {
            "id": "Q25320",
            "label": "Paul Langevin"
          },
          "P577": "1908-00-00",
          "main_subject": [
            "Q413",
            {
              "id": "Q395",
              "label": "mathematics"
            },
            {
              "id": "Q178036",
              "label": "Brownian motion"
            }
          ],
          "instance_of": [
            {
              "id": "Q1545585",
              "label": "stochastic differential equation"
            },
            "Q584537"
          ],
          "topic_main_category": [
            "Q11397",
            "Q677916",
            "Q638328",
            "Q2190991"
          ],
          "P805": {
            "id": "Q20949789",
            "label": "On the theory of brownian motion"
          },
          "P6216": {
            "id": "Q19652",
            "label": "public domain"
          },
          "mag_id": "2780004032",
          "freebase_id": "/m/0d5_gf",
          "openalex_id": "C2780004032",
          "P6104": {
            "id": "Q8487137",
            "label": "WikiProject Mathematics"
          }
        }
      }
    },
    {
      "name": "Robot manipulation",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "The paper benchmarks Diffusion Policy on 15 robot manipulation tasks from 4 different benchmarks.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Manipulator_(device)",
      "wikidata": {
        "id": "Q1587588",
        "label": "manipulator",
        "description": "mechanism designed to grasp and hold items",
        "aliases": [
          "end effector"
        ],
        "claims": {
          "freebase_id": "/m/01f9zf",
          "same_as": {
            "id": "Q606878",
            "label": "remote manipulator"
          },
          "part_of": [
            {
              "id": "Q11012",
              "label": "robot"
            },
            {
              "id": "Q2579259",
              "label": "logging truck"
            }
          ],
          "gnd_id": "4037349-6",
          "loc_id": "sh85080558",
          "subclass_of": [
            {
              "id": "Q517596",
              "label": "mechanism"
            },
            "Q110558047"
          ],
          "P4732": "M03697",
          "image": "FANUC Robot Assembly Demo.jpg",
          "use": [
            "Q5597405",
            "Q108951109"
          ],
          "different_from": [
            "Q110558047",
            "Q136773949"
          ],
          "openalex_id": [
            "C2781347998",
            "C2985527887"
          ],
          "P4342": "manipulator",
          "P8189": "987007548324205171",
          "commons_category": "Handling robots",
          "P13591": "concept/7ce022fb-463f-4bd6-9f7e-5385c760857c"
        }
      }
    },
    {
      "name": "Reinforcement learning",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The paper compares Diffusion Policy against existing robot learning methods that often use reinforcement learning.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": "Q2539",
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": "Q2539",
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            {
              "id": "Q111862379",
              "label": "machine learning method"
            },
            {
              "id": "Q130609847",
              "label": "learning approach"
            }
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Generative model",
      "entity_type": "concept",
      "relation": "proposes",
      "relevance": "The paper leverages powerful generative modeling capabilities of diffusion models for policy learning.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Generative_model",
      "wikidata": {
        "id": "Q5532625",
        "label": "generative model",
        "description": "model for randomly generating observable data in probability and statistics",
        "aliases": [],
        "claims": {
          "subclass_of": "Q3284399",
          "opposite_of": {
            "id": "Q5282087",
            "label": "discriminative model"
          },
          "mag_id": "167966045",
          "freebase_id": "/m/04js0s",
          "openalex_id": "C167966045",
          "use": "Q1152135",
          "described_by_source": {
            "id": "Q133280493",
            "label": "Generative Modeling"
          },
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Model predictive control",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "The paper incorporates receding horizon control, a key concept in model predictive control, into Diffusion Policy.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Model_predictive_control",
      "wikidata": {
        "id": "Q1782962",
        "label": "model predictive control",
        "description": "advanced method of process control",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/04604p",
          "mag_id": "172205157",
          "openalex_id": "C172205157",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Transformer (deep learning)",
      "entity_type": "artifact",
      "relation": "proposes",
      "relevance": "The paper introduces a time-series diffusion transformer as a key technical component for visuomotor policy learning.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
      "wikidata": {
        "id": "Q85810444",
        "label": "transformer",
        "description": "machine-learning model architecture first developed by Google Brain",
        "aliases": [
          "transformer model",
          "transformer architecture",
          "transformers"
        ],
        "claims": {
          "subclass_of": [
            "Q192776",
            {
              "id": "Q113364611",
              "label": "deep learning model"
            }
          ],
          "developer": [
            {
              "id": "Q16927616",
              "label": "Google Brain"
            },
            {
              "id": "Q44749723",
              "label": "Ashish Vaswani"
            },
            "Q30251943"
          ],
          "follows": [
            {
              "id": "Q1457734",
              "label": "recurrent neural network"
            },
            {
              "id": "Q6673524",
              "label": "long short-term memory"
            }
          ],
          "described_by_source": {
            "id": "Q30249683",
            "label": "Attention Is All You Need"
          },
          "google_kg_id": "/g/11hz_m4ssw",
          "has_parts": [
            "Q42586063",
            {
              "id": "Q745243",
              "label": "decoder"
            }
          ],
          "uses": [
            {
              "id": "Q103701642",
              "label": "attention"
            },
            {
              "id": "Q5441227",
              "label": "feedforward neural network"
            }
          ],
          "use": [
            {
              "id": "Q30642",
              "label": "natural language processing"
            },
            {
              "id": "Q844240",
              "label": "computer vision"
            },
            {
              "id": "Q3245113",
              "label": "statistical machine translation"
            },
            {
              "id": "Q1394144",
              "label": "automatic summarization"
            }
          ],
          "schematic": "Transformer, full architecture.png",
          "stack_exchange_tag": "https://ai.stackexchange.com/tags/transformer",
          "P575": "2017-06-12",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Score function",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The paper learns the gradient of the action-distribution score function for policy optimization.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Score_function",
      "wikidata": {
        "id": "Q7435318",
        "label": "Score function",
        "description": "Wikimedia disambiguation page",
        "aliases": [],
        "claims": {
          "instance_of": {
            "id": "Q4167410",
            "label": "Wikimedia disambiguation page"
          }
        }
      }
    },
    {
      "name": "Stochastic process",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Diffusion models fundamentally rely on stochastic processes to model action generation and policy learning.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Stochastic_process",
      "wikidata": {
        "id": "Q176737",
        "label": "stochastic process",
        "description": "mathematical object usually defined as a collection of random variables",
        "aliases": [
          "random process",
          "stochastic processes"
        ],
        "claims": {
          "P349": "00564752",
          "freebase_id": "/m/0cvtw",
          "part_of": {
            "id": "Q1071239",
            "label": "stochastic"
          },
          "P1051": "7710",
          "topic_main_category": {
            "id": "Q8806217",
            "label": "Category:Stochastic processes"
          },
          "commons_category": "Stochastic processes",
          "described_by_source": "Q124737636",
          "britannica_id": "topic/stochastic-process",
          "mesh_id": "D013269",
          "P3285": "60Gxx",
          "P508": "20545",
          "P2892": "C0038347",
          "P3827": "stochastic-processes",
          "quora_topic_id": "Stochastic-Processes",
          "subclass_of": [
            {
              "id": "Q246672",
              "label": "mathematical object"
            },
            {
              "id": "Q856215",
              "label": "indexed family"
            }
          ],
          "babelnet_id": "00074331n",
          "P4746": "133839",
          "P2924": "3838851",
          "P3219": "stochastiques-processus-aleatoires",
          "loc_id": "sh85128181",
          "mesh_tree_code": [
            "E05.318.740.996",
            "G17.830",
            "N05.715.360.750.770",
            "N06.850.520.830.996"
          ],
          "mag_id": [
            "8272713",
            "92703954"
          ],
          "P8408": "StochasticProcess",
          "P4215": "stochastic process",
          "P1552": {
            "id": "Q176640",
            "label": "randomness"
          },
          "P8814": "13583099-n",
          "P268": "119326416",
          "P950": "XX4576445",
          "gnd_id": "4057630-9",
          "P3553": "19699543",
          "P2179": "10003700",
          "P7305": "3979832",
          "P2004": "48588",
          "P2347": "11400",
          "P8189": "987007536303605171",
          "P4839": "Entity[\"Concept\", \"StochasticProcess::c4479\"]",
          "P2812": "StochasticProcess",
          "openalex_id": [
            "C8272713",
            "C13929819",
            "C2984125019",
            "C92703954"
          ],
          "P4342": "stokastisk",
          "P691": "ph116285",
          "P5008": {
            "id": "Q6173448",
            "label": "Wikipedia:Vital articles/Level/4"
          },
          "instance_of": [
            {
              "id": "Q24034552",
              "label": "mathematical concept"
            },
            {
              "id": "Q116505632",
              "label": "type of process"
            }
          ],
          "stack_exchange_tag": "https://mathoverflow.net/tags/stochastic-processes",
          "image": "BMonSphere.jpg",
          "P3911": "15225-1",
          "openalex_topic_id": "296296",
          "P11514": "sluchainyi-protsess-ba199d",
          "P10376": [
            "agricultural-and-biological-sciences/stochastic-process",
            "chemistry/stochastic-process",
            "computer-science/stochastic-process",
            "earth-and-planetary-sciences/stochastic-process",
            "neuroscience/stochastic-process",
            "physics-and-astronomy/stochastic-process",
            "physics-and-astronomy/random-processes",
            "social-sciences/random-processes"
          ],
          "P3916": "concept7525",
          "P6104": {
            "id": "Q8487137",
            "label": "WikiProject Mathematics"
          },
          "P2738": {
            "id": "Q23766486",
            "label": "list of values as qualifiers"
          },
          "topic_maintained_by": {
            "id": "Q15634422",
            "label": "Template:Stochastic processes"
          },
          "P2163": "1133519",
          "P9621": "processo-stocastico",
          "P9941": "processo-aleatorio",
          "P4223": "processi-stocastici",
          "P13591": "concept/f883b6a5-6c94-4fd2-8705-d6f344d2f2f7",
          "P1269": "Q5862903",
          "P1036": "519.23",
          "has_parts": "Q176623"
        }
      }
    }
  ]
}