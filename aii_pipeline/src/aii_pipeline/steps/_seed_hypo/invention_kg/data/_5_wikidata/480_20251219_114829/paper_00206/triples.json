{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Matthews correlation coefficient",
      "relation": "proposes",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Phi_coefficient",
      "relevance": "The paper proposes MCC as the most reliable single metric for evaluating binary classifiers and recommends it as a standard measure across all fields.",
      "wikidata": {
        "id": "Q4811327",
        "label": "Phi coefficient",
        "description": "type of coefficient",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/065z539",
          "mag_id": "110229601",
          "P2812": "PhiCoefficient",
          "openalex_id": "C164085508",
          "P6104": {
            "id": "Q8487137",
            "label": "WikiProject Mathematics"
          }
        }
      }
    },
    {
      "name": "Confusion matrix",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Confusion_matrix",
      "relevance": "The paper evaluates metrics that summarize two-class confusion matrices, which contain true positives, true negatives, false positives, and false negatives.",
      "wikidata": {
        "id": "Q2709591",
        "label": "confusion matrix",
        "description": "table layout for visualizing performance; also called an error matrix",
        "aliases": [
          "error matrix",
          "contingency table"
        ],
        "claims": {
          "freebase_id": "/m/03gqxq",
          "subclass_of": "Q44337",
          "quora_topic_id": "Confusion-Matrix",
          "mag_id": "138602881",
          "P9100": "confusion-matrix",
          "openalex_id": "C138602881"
        }
      }
    },
    {
      "name": "Binary classification",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Binary_classification",
      "relevance": "The paper focuses on evaluating binary (two-class) classification performance, which is a fundamental task in machine learning.",
      "wikidata": {
        "id": "Q17005494",
        "label": "binary classification",
        "description": "the task of classifying the elements of a given set into two groups (predicting which group each one belongs to) on the basis of a classification rule",
        "aliases": [
          "dichotomous trait"
        ],
        "claims": {
          "subclass_of": [
            "Q1744628",
            "Q1211967"
          ],
          "mag_id": "66905080",
          "P9100": "binary-classification",
          "freebase_id": "/m/01d3xn",
          "openalex_id": "C66905080",
          "google_kg_id": "/g/121w63p_",
          "openalex_topic_id": "18648",
          "opposite_of": {
            "id": "Q6934605",
            "label": "Multiclass classification"
          },
          "uses": "Q1744627"
        }
      }
    },
    {
      "name": "Balanced accuracy",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers",
      "relevance": "The paper compares MCC against balanced accuracy as an alternative metric for evaluating binary classifiers on imbalanced datasets.",
      "wikidata": {
        "id": "Q18206917",
        "label": "evaluation of binary classifiers",
        "description": "overview about the evaluation of binary classifiers",
        "aliases": [],
        "claims": {
          "mag_id": "2779130847"
        }
      }
    },
    {
      "name": "F-score",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/F-score",
      "relevance": "The paper compares MCC to the F1 score, showing that MCC is more informative for binary classification evaluation.",
      "wikidata": {
        "id": "Q6975395",
        "label": "F1 score",
        "description": "measure of a test's accuracy",
        "aliases": [
          "F-score",
          "F-measure",
          "F₁ score"
        ],
        "claims": {
          "mag_id": "148524875",
          "freebase_id": "/m/0bcdln",
          "openalex_id": "C148524875",
          "instance_of": "Q59772171",
          "subclass_of": "Q272035"
        }
      }
    },
    {
      "name": "Accuracy (classification)",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Accuracy_and_precision",
      "relevance": "The paper contrasts MCC with standard accuracy, which can be misleading on imbalanced datasets.",
      "wikidata": {
        "id": "Q272035",
        "label": "accuracy and precision",
        "description": "measures of observational error",
        "aliases": [
          "Inaccuracy and imprecision",
          "accuracy",
          "accurate",
          "precision and accuracy",
          "accuracy vs. precision",
          "precision vs. accuracy",
          "test inaccuracy",
          "accuracy (trueness and precision)",
          "Data Accuracy",
          "precision",
          "trueness and precision)"
        ],
        "claims": {
          "freebase_id": "/m/0bjjd",
          "has_parts": [
            {
              "id": "Q962365",
              "label": "precision"
            },
            {
              "id": "Q1298969",
              "label": "accuracy"
            }
          ],
          "topic_main_category": {
            "id": "Q18744590",
            "label": "Category:Accuracy and precision"
          },
          "subclass_of": [
            {
              "id": "Q192276",
              "label": "measure"
            },
            "Q2091629"
          ],
          "quora_topic_id": "Accuracy",
          "commons_category": "Accuracy and precision",
          "britannica_id": "science/accuracy",
          "P4732": "I02995",
          "mesh_id": "D000068598",
          "mesh_tree_code": [
            "E05.318.308.028",
            "E05.318.370.725.250",
            "L01.399.250.202",
            "N05.715.360.300.202",
            "N05.715.360.325.685.250"
          ],
          "P7775": "Accuracy_and_precision",
          "mag_id": "202799725",
          "P8408": "Accuracy",
          "openalex_id": "C202799725",
          "P2347": "20173",
          "P1269": [
            {
              "id": "Q12453",
              "label": "measurement"
            },
            {
              "id": "Q194292",
              "label": "operations research"
            }
          ],
          "P2892": "C0242483",
          "P268": "181002182",
          "described_by_source": [
            {
              "id": "Q867541",
              "label": "Encyclopædia Britannica 11th edition"
            },
            "Q133257572"
          ],
          "image": "Accuracy (trueness and precision).svg",
          "P11093": "dogruluk"
        }
      }
    },
    {
      "name": "Youden's J statistic",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Youden's_J_statistic",
      "relevance": "The paper identifies Youden's J statistic (informedness) as another related metric with specific use cases for classifier evaluation.",
      "wikidata": {
        "id": "Q8057732",
        "label": "Youden's J statistic",
        "description": "Index that describes the performance of a dichotomous diagnostic test",
        "aliases": [],
        "claims": {
          "mag_id": "43346845",
          "freebase_id": "/m/03ctb26",
          "instance_of": {
            "id": "Q24034552",
            "label": "mathematical concept"
          },
          "openalex_id": "C43346845"
        }
      }
    }
  ]
}