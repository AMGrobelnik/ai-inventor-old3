{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Reinforcement learning",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "relevance": "The paper uses multi-agent reinforcement learning as the core learning mechanism for training robot manipulation policies.",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            "Q111862379",
            "Q130609847"
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Actor-critic algorithm",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Actor-critic_algorithm",
      "relevance": "The paper employs the Soft Actor-Critic (SAC) algorithm, which is a variant of actor-critic methods for training sub-policies.",
      "wikidata": {
        "id": "Q131936605",
        "label": "Actor-critic algorithm",
        "description": "reinforcement learning algorithms that combine policy and value estimation",
        "aliases": [],
        "claims": {
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Robot learning",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Robot_learning",
      "relevance": "The paper addresses robot learning by training a Panda robot to perform grasping and object manipulation tasks.",
      "wikidata": {
        "id": "Q7353390",
        "label": "robot learning",
        "description": "machine learning for robots",
        "aliases": [],
        "claims": {
          "mag_id": "188888258",
          "freebase_id": "/m/093nl0",
          "openalex_id": "C188888258",
          "P1269": "Q170978",
          "subclass_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "P13397": "robot-learning"
        }
      }
    },
    {
      "name": "Robotic arm",
      "relation": "uses",
      "entity_type": "tool",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Robotic_arm",
      "relevance": "The paper uses a Franka Emika Panda robotic arm as the experimental platform for evaluating the multi-stage learning approach.",
      "wikidata": {
        "id": "Q40687",
        "label": "robotic arm",
        "description": "type of mechanical arm with similar functions to a human arm",
        "aliases": [
          "robot arm"
        ],
        "claims": {
          "commons_category": "Handling robots",
          "freebase_id": "/m/02qf6jc",
          "subclass_of": [
            "Q11012",
            {
              "id": "Q30587750",
              "label": "mechanical arm"
            }
          ],
          "quora_topic_id": "Robotic-Arm",
          "part_of": "Q11012",
          "mag_id": "150415221",
          "stack_exchange_tag": "https://robotics.stackexchange.com/tags/robotic-arm",
          "P8408": "RoboticArm",
          "image": [
            "Blueblack preview featured.jpg",
            "STS-114 Steve Robinson on Canadarm2.jpg"
          ],
          "P3451": "HTV-6 final approach towards the International Space Station (3).jpg",
          "openalex_id": [
            "C150415221",
            "C2988191880",
            "C2987841220"
          ],
          "P13397": "robotic-arm"
        }
      }
    },
    {
      "name": "Supervised learning",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Supervised_learning",
      "relevance": "The high-level stage selector is trained using supervised learning to coordinate between the six sub-policies.",
      "wikidata": {
        "id": "Q334384",
        "label": "supervised learning",
        "description": "machine learning task of learning a function that maps an input to an output based on example input-output pairs",
        "aliases": [
          "supervised machine learning"
        ],
        "claims": {
          "freebase_id": "/m/0586t",
          "part_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "instance_of": {
            "id": "Q1047113",
            "label": "field of study"
          },
          "subclass_of": [
            {
              "id": "Q2539",
              "label": "machine learning"
            },
            "Q111862379"
          ],
          "opposite_of": "Q1152135",
          "mesh_id": "D000069553",
          "quora_topic_id": "Supervised-Learning",
          "babelnet_id": "01366724n",
          "P2179": "10010259",
          "loc_id": "sh94008290",
          "P1245": "1706209",
          "mag_id": "136389625",
          "P9100": "supervised-learning",
          "P9982": "28740",
          "P8189": "987007561023305171",
          "P1535": {
            "id": "Q29169143",
            "label": "data scientist"
          },
          "P2579": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "openalex_id": "C136389625",
          "openalex_topic_id": [
            "204028",
            "216638"
          ],
          "P7502": "Supervised_Learning-6AM",
          "uses": "Q5282087",
          "topic_main_category": "Q30640394",
          "mesh_tree_code": [
            "G17.035.250.500.500",
            "L01.224.050.375.530.500"
          ],
          "P1149": "Q325.75",
          "P11662": "3582082",
          "P3235": "supervised-learning",
          "P13591": "concept/cf583102-236b-4653-a870-fc87150b4484",
          "P508": "79136"
        }
      }
    },
    {
      "name": "Imitation learning",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Imitation_learning",
      "relevance": "The paper compares against imitation-only baselines and mentions learning from demonstrations in the context of traditional approaches.",
      "wikidata": {
        "id": "Q124742024",
        "label": "imitation learning",
        "description": "machine learning technique where agents learn from demonstrations",
        "aliases": [
          "behavior cloning",
          "behaviour cloning",
          "learning from demonstration"
        ],
        "claims": {
          "subclass_of": {
            "id": "Q7353390",
            "label": "robot learning"
          },
          "instance_of": "Q117348143",
          "P1269": "Q170978",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Multi-stage learning",
      "relation": "proposes",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "relevance": "The paper proposes a novel multi-stage learning approach that decomposes grasp-constrained manipulation into independently trained sub-policies.",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            "Q111862379",
            "Q130609847"
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Object manipulation",
      "relation": "proposes",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Robot_learning",
      "relevance": "The paper addresses grasp-constrained object manipulation as the primary task with obstacles and constraints on object grasping.",
      "wikidata": {
        "id": "Q7353390",
        "label": "robot learning",
        "description": "machine learning for robots",
        "aliases": [],
        "claims": {
          "mag_id": "188888258",
          "freebase_id": "/m/093nl0",
          "openalex_id": "C188888258",
          "P1269": "Q170978",
          "subclass_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "P13397": "robot-learning"
        }
      }
    }
  ]
}