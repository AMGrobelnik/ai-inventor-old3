{
  "paper_type": "survey",
  "triples": [
    {
      "name": "Deep reinforcement learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "The paper reviews and systematically analyzes DRL methods as the primary approach for mobile robot navigation.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_reinforcement_learning",
      "wikidata": {
        "id": "Q65079156",
        "label": "deep reinforcement learning",
        "description": "techniques combining deep learning and reinforcement learning principles to create efficient machine learning algorithms",
        "aliases": [
          "DRL"
        ],
        "claims": {
          "google_kg_id": [
            "/g/11h0mpm7vy",
            "/g/11f6y3p_tx"
          ],
          "subclass_of": [
            {
              "id": "Q830687",
              "label": "reinforcement learning"
            },
            {
              "id": "Q197536",
              "label": "deep learning"
            }
          ],
          "P10376": "computer-science/deep-reinforcement-learning"
        }
      }
    },
    {
      "name": "Robot navigation",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "Robot navigation is the fundamental problem that the paper addresses using DRL techniques.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Robot_navigation",
      "wikidata": {
        "id": "Q6887224",
        "label": "robot navigation",
        "description": "robot's ability to determine its own position in its frame of reference and then to plan a path towards some goal location",
        "aliases": [
          "mobile robot navigation"
        ],
        "claims": {
          "subclass_of": "Q102066",
          "mag_id": "26990112",
          "freebase_id": "/m/03d4p2j",
          "openalex_id": "C26990112",
          "topic_main_category": {
            "id": "Q8670736",
            "label": "Category:Robot navigation"
          }
        }
      }
    },
    {
      "name": "Obstacle avoidance",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "Local obstacle avoidance is one of the four typical DRL application scenarios reviewed in the paper.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Obstacle_avoidance",
      "wikidata": {
        "id": "Q7075535",
        "label": "obstacle avoidance",
        "description": "in robotics, a task of satisfying some objective subject to non-intersection or non-collision position constraints",
        "aliases": [
          "collision avoidance",
          "obstacle navigation"
        ],
        "claims": {
          "P3827": "obstacle-avoidance",
          "mag_id": "6683253",
          "freebase_id": "/m/025_qqj",
          "openalex_id": "C6683253",
          "P1269": "Q170978",
          "image": "01Cruise-E-Ultrasonic Intelligent Obstacle Avoidance.gif",
          "commons_category": "Obstacle avoidance",
          "subclass_of": [
            "Q111016707",
            {
              "id": "Q131452884",
              "label": "path planning"
            }
          ]
        }
      }
    },
    {
      "name": "Reinforcement learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Reinforcement learning is the foundational machine learning paradigm that deep reinforcement learning builds upon.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": "Q2539",
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": "Q2539",
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            {
              "id": "Q111862379",
              "label": "machine learning method"
            },
            {
              "id": "Q130609847",
              "label": "learning approach"
            }
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    }
  ]
}