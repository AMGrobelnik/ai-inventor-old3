{
  "paper_type": "survey",
  "triples": [
    {
      "name": "Reinforcement learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Foundational ML paradigm for sequential decision-making that the paper builds upon and reviews.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": "Q2539",
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": "Q2539",
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            {
              "id": "Q111862379",
              "label": "machine learning method"
            },
            {
              "id": "Q130609847",
              "label": "learning approach"
            }
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Deep learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Technique that enables RL methods to handle high-dimensional environments, core to the paper's focus.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_learning",
      "wikidata": {
        "id": "Q197536",
        "label": "deep learning",
        "description": "branch of machine learning",
        "aliases": [
          "DL",
          "deep machine learning",
          "hierarchical learning",
          "deep structured learning"
        ],
        "claims": {
          "freebase_id": "/m/0h1fn8h",
          "P61": [
            {
              "id": "Q3571662",
              "label": "Yann Le Cun"
            },
            {
              "id": "Q92894",
              "label": "Geoffrey Hinton"
            }
          ],
          "topic_main_category": {
            "id": "Q24070291",
            "label": "Category:Deep learning"
          },
          "quora_topic_id": "Deep-Learning",
          "P3219": "apprentissage-profond-deep-learning",
          "subclass_of": {
            "id": "Q111862379",
            "label": "machine learning method"
          },
          "commons_category": "Deep learning",
          "P4342": [
            "dyplæring",
            "dyp_læring"
          ],
          "P6363": "http://data.thenextweb.com/tnw/entity/deep_learning",
          "use": {
            "id": "Q11660",
            "label": "artificial intelligence"
          },
          "P3553": "19813032",
          "mesh_id": "D000077321",
          "mesh_tree_code": [
            "G17.035.250.500.250",
            "G17.485.500",
            "L01.224.050.375.530.250",
            "L01.224.050.375.605.500"
          ],
          "mag_id": "108583219",
          "P3984": "deeplearning",
          "P7502": "Deep_learning-PE5E9Y",
          "P9100": [
            "deep-learning",
            "deep-learning-tutorial",
            "deeplearning"
          ],
          "P8529": "461103",
          "P9526": "Deep_Learning",
          "image": "Deep Learning.jpg",
          "P6802": "Computer vision sample in Simón Bolivar Avenue, Quito.jpg",
          "openalex_id": [
            "C108583219",
            "C2984842247"
          ],
          "P2347": "39324",
          "openalex_topic_id": [
            "216836",
            "221130"
          ],
          "P691": "ph1042930",
          "P11408": "ディープラーニング",
          "P8687": "+95159",
          "P5844": "deep-learning_(Neologismi)",
          "P2892": "C4704761",
          "P11196": "深度学习",
          "P12086": "Deep_learning",
          "P8189": "987011038167805171",
          "loc_id": "sh2021006947",
          "P1368": "000350792",
          "P9346": "deep-learning",
          "P3911": "30476-3",
          "P6900": "ディープラーニング",
          "P13397": "deep+learning",
          "P508": "78027",
          "P268": "17706295v",
          "gnd_id": "1135597375",
          "P3235": "deep-learning",
          "stack_exchange_tag": [
            "https://ai.stackexchange.com/tags/deep-learning",
            "https://or.stackexchange.com/tags/deep-learning",
            "https://stats.stackexchange.com/tags/deep-learning"
          ],
          "P13591": "concept/21bbd7b7-62b1-4bd8-844d-00f4bc0ccd62",
          "P1036": "006.31",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Deep reinforcement learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "The primary technique reviewed; combines deep learning with RL for sophisticated agent control.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_reinforcement_learning",
      "wikidata": {
        "id": "Q65079156",
        "label": "deep reinforcement learning",
        "description": "techniques combining deep learning and reinforcement learning principles to create efficient machine learning algorithms",
        "aliases": [
          "DRL"
        ],
        "claims": {
          "google_kg_id": [
            "/g/11h0mpm7vy",
            "/g/11f6y3p_tx"
          ],
          "subclass_of": [
            {
              "id": "Q830687",
              "label": "reinforcement learning"
            },
            {
              "id": "Q197536",
              "label": "deep learning"
            }
          ],
          "P10376": "computer-science/deep-reinforcement-learning"
        }
      }
    },
    {
      "name": "Multi-agent system",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Core domain of the paper; systems where multiple agents must communicate and cooperate.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Multi-agent_system",
      "wikidata": {
        "id": "Q529909",
        "label": "multi-agent system",
        "description": "built of multiple interacting agents",
        "aliases": [
          "multi-agent systems",
          "multiagent system",
          "multiagent systems",
          "MAS"
        ],
        "claims": {
          "freebase_id": "/m/03rt8n",
          "topic_main_category": {
            "id": "Q8645694",
            "label": "Category:Multi-agent systems"
          },
          "quora_topic_id": "Multi-Agent-Systems",
          "subclass_of": {
            "id": "Q2429814",
            "label": "software system"
          },
          "gnd_id": "4389058-1",
          "loc_id": "sh2009010910",
          "P2163": "1749717",
          "P508": "63794",
          "mag_id": "41550386",
          "P8408": "MultiAgentSystem",
          "openalex_id": "C41550386",
          "P691": "ph312564",
          "P13591": "concept/a76b27f9-56dd-4c7d-a364-58f77f59c34a",
          "instance_of": "Q96116695",
          "P1036": [
            "006.3",
            "006.30285436"
          ]
        }
      }
    },
    {
      "name": "Transfer learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Technique reviewed in the context of multiagent learning for knowledge transfer across agents.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transfer_learning",
      "wikidata": {
        "id": "Q6027324",
        "label": "transfer learning",
        "description": "research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem",
        "aliases": [
          "inductive transfer"
        ],
        "claims": {
          "subclass_of": "Q2539",
          "quora_topic_id": "Transfer-Learning",
          "part_of": "Q2539",
          "mag_id": "77075516",
          "freebase_id": "/m/0b6vrv",
          "instance_of": {
            "id": "Q28643",
            "label": "paradigm"
          },
          "uses": {
            "id": "Q6015447",
            "label": "incremental computation"
          },
          "P9100": "transfer-learning",
          "openalex_id": "C77075516",
          "schematic": "Transfer learning.svg",
          "different_from": "Q1820378",
          "mesh_id": "D000098410",
          "mesh_tree_code": [
            "G17.035.250.500.625",
            "L01.224.050.375.530.625"
          ],
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Partially observable Markov decision process",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Framework for handling partial observability challenges in multiagent environments.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process",
      "wikidata": {
        "id": "Q176814",
        "label": "partially observable Markov decision process",
        "description": "generalization of a Markov decision process",
        "aliases": [
          "POMDP"
        ],
        "claims": {
          "freebase_id": "/m/08p0k3",
          "P138": "Q176659",
          "P144": "Q176789",
          "mag_id": "17098449",
          "openalex_id": "C17098449",
          "openalex_topic_id": "41685"
        }
      }
    }
  ]
}