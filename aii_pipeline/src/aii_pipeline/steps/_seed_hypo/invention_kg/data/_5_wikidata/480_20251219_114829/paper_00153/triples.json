{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Reinforcement learning",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "relevance": "Foundational machine learning paradigm that CQL builds upon for learning from agent-environment interactions.",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": "Q2539",
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": "Q2539",
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            {
              "id": "Q111862379",
              "label": "machine learning method"
            },
            {
              "id": "Q130609847",
              "label": "learning approach"
            }
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Q-learning",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Q-learning",
      "relevance": "Core value-based RL algorithm that CQL augments with conservatism to address offline RL challenges.",
      "wikidata": {
        "id": "Q2664563",
        "label": "Q-learning",
        "description": "model-free reinforcement learning algorithm",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/04pvn7",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/q-learning",
            "https://ai.stackexchange.com/tags/q-learning"
          ],
          "quora_topic_id": "Q-learning",
          "P1269": {
            "id": "Q830687",
            "label": "reinforcement learning"
          },
          "mag_id": "188116033",
          "instance_of": {
            "id": "Q8366",
            "label": "algorithm"
          },
          "subclass_of": {
            "id": "Q63788448",
            "label": "model-free reinforcement learning"
          },
          "P2179": "10010329",
          "openalex_id": "C188116033",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Deep reinforcement learning",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_reinforcement_learning",
      "relevance": "CQL is implemented as a deep Q-learning method combining neural networks with Q-learning for large state spaces.",
      "wikidata": {
        "id": "Q65079156",
        "label": "deep reinforcement learning",
        "description": "techniques combining deep learning and reinforcement learning principles to create efficient machine learning algorithms",
        "aliases": [
          "DRL"
        ],
        "claims": {
          "google_kg_id": [
            "/g/11h0mpm7vy",
            "/g/11f6y3p_tx"
          ],
          "subclass_of": [
            {
              "id": "Q830687",
              "label": "reinforcement learning"
            },
            {
              "id": "Q197536",
              "label": "deep learning"
            }
          ],
          "P10376": "computer-science/deep-reinforcement-learning"
        }
      }
    },
    {
      "name": "Actor-critic algorithm",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Actor-critic_algorithm",
      "relevance": "CQL can be incorporated into actor-critic implementations, extending its applicability beyond pure Q-learning.",
      "wikidata": {
        "id": "Q131936605",
        "label": "Actor-critic algorithm",
        "description": "reinforcement learning algorithms that combine policy and value estimation",
        "aliases": [],
        "claims": {
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Offline learning",
      "relation": "proposes",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Offline_learning",
      "relevance": "CQL is a novel algorithm for offline RL that learns policies from fixed datasets without additional environment interaction.",
      "wikidata": {
        "id": "Q7079636",
        "label": "offline machine learning",
        "description": "method of machine learning",
        "aliases": [
          "batch learning",
          "cumulated modification learning",
          "epochal learning",
          "block learning"
        ],
        "claims": {
          "subclass_of": "Q2539",
          "opposite_of": "Q7094097",
          "mag_id": "2780490138",
          "freebase_id": "/m/02qnykr",
          "openalex_id": "C2780490138"
        }
      }
    },
    {
      "name": "Bellman equation",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Bellman_equation",
      "relevance": "CQL augments the standard Bellman error objective with a Q-value regularizer for conservative learning.",
      "wikidata": {
        "id": "Q1430750",
        "label": "Bellman equation",
        "description": "necessary condition for optimality associated with dynamic programming",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/04k_pc",
          "quora_topic_id": "Bellman-Equation",
          "mag_id": "14646407",
          "P138": "Q441199",
          "P1269": {
            "id": "Q1971426",
            "label": "optimal control"
          },
          "P2534": "V(x) = \\max_{a \\in \\Gamma (x) } \\{ F(x,a) + \\beta V(T(x,a)) \\}",
          "opposite_of": "Q3302775",
          "openalex_id": "C14646407",
          "openalex_topic_id": [
            "216586",
            "56096"
          ],
          "instance_of": {
            "id": "Q24034552",
            "label": "mathematical concept"
          },
          "P6104": {
            "id": "Q8487137",
            "label": "WikiProject Mathematics"
          },
          "P11514": "uravnenie-bellmana-29eb69",
          "P2924": "1854149"
        }
      }
    },
    {
      "name": "Domain adaptation",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Domain_adaptation",
      "relevance": "Addresses distributional shift between training dataset and learned policy, a core challenge CQL solves.",
      "wikidata": {
        "id": "Q19246213",
        "label": "Domain Adaptation",
        "description": "field associated with machine learning and transfer learning",
        "aliases": [],
        "claims": {
          "mag_id": "2776434776",
          "freebase_id": "/m/012vqfs3",
          "P9100": "domain-adaptation",
          "openalex_id": "C2776434776",
          "subclass_of": {
            "id": "Q830687",
            "label": "reinforcement learning"
          }
        }
      }
    },
    {
      "name": "Policy gradient method",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Policy_gradient_method",
      "relevance": "CQL can be incorporated into policy learning procedures as part of its integrated approach to offline RL.",
      "wikidata": {
        "id": "Q113840014",
        "label": "policy-gradient method",
        "description": "class of reinforcement learning algorithms",
        "aliases": [
          "policy gradient method",
          "policy gradient"
        ],
        "claims": {
          "subclass_of": {
            "id": "Q830687",
            "label": "reinforcement learning"
          },
          "P9526": "Policy_gradient_methods",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    }
  ]
}