{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Reinforcement learning",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "relevance": "The paper applies reward machines to improve reinforcement learning algorithms for better sample efficiency.",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            "Q111862379",
            "Q130609847"
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Finite-state machine",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Finite-state_machine",
      "relevance": "Reward machines are formalized as a type of finite state machine that specifies reward function structure.",
      "wikidata": {
        "id": "Q176452",
        "label": "finite-state machine",
        "description": "mathematical model of computation; abstract machine that can be in exactly one of a finite number of states at any given time",
        "aliases": [
          "FSM",
          "finite-state automaton",
          "finite automaton",
          "FA",
          "finite automata",
          "state machine"
        ],
        "claims": {
          "commons_category": "Finite state machine",
          "has_parts": "Q599031",
          "freebase_id": "/m/02ykc",
          "stack_exchange_tag": "https://stackoverflow.com/tags/fsm",
          "subclass_of": {
            "id": "Q787114",
            "label": "abstract machine"
          },
          "described_by_source": "Q124355862",
          "babelnet_id": "00212740n",
          "P5106": [
            "finiteStateMachine",
            "finiteStateAutomaton"
          ],
          "quora_topic_id": "Finite-State-Machines",
          "P1245": "956790",
          "mag_id": "167822520",
          "topic_main_category": {
            "id": "Q25304515",
            "label": "Category:Finite automata"
          },
          "openalex_id": [
            "C167822520",
            "C2983497884"
          ],
          "P691": "ph210246",
          "P6564": "finite-state-machines",
          "P9621": "automa-a-stati-finiti",
          "P9100": "finite-state-machine",
          "opposite_of": "Q137172521"
        }
      }
    },
    {
      "name": "Q-learning",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Q-learning",
      "relevance": "Q-learning is an off-policy reinforcement learning algorithm that the paper uses with reward structure.",
      "wikidata": {
        "id": "Q2664563",
        "label": "Q-learning",
        "description": "model-free reinforcement learning algorithm",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/04pvn7",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/q-learning",
            "https://ai.stackexchange.com/tags/q-learning"
          ],
          "quora_topic_id": "Q-learning",
          "P1269": {
            "id": "Q830687",
            "label": "reinforcement learning"
          },
          "mag_id": "188116033",
          "instance_of": "Q8366",
          "subclass_of": "Q63788448",
          "P2179": "10010329",
          "openalex_id": "C188116033",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Linear temporal logic",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Linear_temporal_logic",
      "relevance": "Reward machines support temporally extended properties typical of linear temporal logic for non-Markovian rewards.",
      "wikidata": {
        "id": "Q1536492",
        "label": "linear temporal logic",
        "description": "field of mathematical logic",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/034swn",
          "commons_category": "Linear temporal logic",
          "quora_topic_id": "Linear-Temporal-Logic",
          "mag_id": "4777664",
          "openalex_id": "C4777664",
          "google_kg_id": "/g/11hgk25c3b",
          "subclass_of": [
            "Q210841",
            {
              "id": "Q781833",
              "label": "temporal logic"
            }
          ],
          "stack_exchange_tag": "https://cs.stackexchange.com/tags/linear-temporal-logic"
        }
      }
    },
    {
      "name": "Regular language",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Regular_language",
      "relevance": "Reward machines have the expressive power of a regular language, supporting loops, sequences, and conditionals.",
      "wikidata": {
        "id": "Q752532",
        "label": "regular language",
        "description": "formal language that can be expressed using a regular expression",
        "aliases": [
          "rational language"
        ],
        "claims": {
          "freebase_id": "/m/06f10",
          "quora_topic_id": "Regular-Language",
          "subclass_of": {
            "id": "Q729271",
            "label": "context-free language"
          },
          "P6564": "regular-languages",
          "commons_category": "Regular language",
          "mag_id": "52370388",
          "different_from": {
            "id": "Q3475685",
            "label": "schematic language"
          },
          "openalex_id": "C52370388",
          "P691": "ph237421",
          "P2534": "L\\in\\mathrm{REG}\\Leftrightarrow\\exists A\\in\\mathrm{FSM}:L(A)=L",
          "P7235": [
            "\\mathrm{FSM}",
            "L"
          ],
          "P6104": {
            "id": "Q8487137",
            "label": "WikiProject Mathematics"
          },
          "P7726": "RegularLanguage",
          "P9621": "linguaggio-regolare",
          "P7276": "REGUL%C3%81RN%C3%8D%20JAZYK"
        }
      }
    },
    {
      "name": "Hierarchical task network",
      "relation": "proposes",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Hierarchical_task_network",
      "relevance": "The paper proposes task decomposition methodologies using reward machines to enable hierarchical learning in reinforcement learning.",
      "wikidata": {
        "id": "Q5753136",
        "label": "Hierarchical task network",
        "description": "approach to automated planning",
        "aliases": [],
        "claims": {
          "mag_id": "129250720",
          "freebase_id": "/m/08l5wk"
        }
      }
    }
  ]
}