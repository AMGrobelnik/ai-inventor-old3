{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Reinforcement learning",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "relevance": "IRL is a sub-problem within reinforcement learning where the reward function must be inferred from expert behavior.",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            "Q111862379",
            "Q130609847"
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Markov decision process",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Markov_decision_process",
      "relevance": "The paper uses MDPs as the underlying mathematical framework for modeling the decision-making problem.",
      "wikidata": {
        "id": "Q176789",
        "label": "Markov decision process",
        "description": "mathematical model for sequential decision making under uncertainty",
        "aliases": [
          "MDP",
          "MDPs"
        ],
        "claims": {
          "P138": "Q176659",
          "freebase_id": "/m/048gl8",
          "P1051": "7713",
          "P4969": {
            "id": "Q176814",
            "label": "partially observable Markov decision process"
          },
          "mag_id": "106189395",
          "openalex_id": "C106189395",
          "subclass_of": [
            "Q1331926",
            "Q176737"
          ],
          "openalex_topic_id": "56113",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Apprenticeship learning",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Apprenticeship_learning",
      "relevance": "Apprenticeship learning is a key application domain where reward functions are learned by observing an expert's demonstrations.",
      "wikidata": {
        "id": "Q4781707",
        "label": "Apprenticeship learning",
        "description": "Concept in artificial intelligence",
        "aliases": [],
        "claims": {
          "mag_id": "2780254194",
          "freebase_id": "/m/04n1tc_"
        }
      }
    },
    {
      "name": "Bayesian inference",
      "relation": "proposes",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Bayesian_inference",
      "relevance": "The paper introduces a novel Bayesian approach to combine prior knowledge with expert evidence to derive a probability distribution over reward functions.",
      "wikidata": {
        "id": "Q812535",
        "label": "Bayesian inference",
        "description": "method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available",
        "aliases": [
          "Bayesian analysis",
          "Bayes' solution",
          "Bayesian approach",
          "Bayesian method",
          "Bayes inference",
          "Bayesian updating"
        ],
        "claims": {
          "gnd_id": "4144220-9",
          "P508": "36249",
          "topic_main_category": {
            "id": "Q8293925",
            "label": "Category:Bayesian inference"
          },
          "freebase_id": "/m/0d5kn",
          "P1296": "0281295",
          "P1051": "7719",
          "P138": "Q208452",
          "P2534": "P(H\\mid E) = \\frac{P(E\\mid H) \\cdot P(H)}{P(E)}",
          "quora_topic_id": "Bayesian-Inference",
          "P3827": [
            "bayesian-inference",
            "bayesian-analysis",
            "bayesian-confirmation-theory"
          ],
          "loc_id": "sh85012506",
          "mag_id": "160234255",
          "P2347": "17803",
          "P9100": "bayesian-inference",
          "P2179": "10003664",
          "P2004": "16108",
          "P8189": "987007282424705171",
          "openalex_id": "C160234255",
          "P5008": {
            "id": "Q6173448",
            "label": "Wikipedia:Vital articles/Level/4"
          },
          "P691": "ph135362",
          "P3222": "bayes-inferens",
          "openalex_topic_id": [
            "533808",
            "143282",
            "316492"
          ],
          "stack_exchange_tag": [
            "https://stats.stackexchange.com/tags/bayesian",
            "https://philosophy.stackexchange.com/tags/bayesian",
            "https://stackoverflow.com/tags/bayesian"
          ],
          "P6104": {
            "id": "Q8487137",
            "label": "WikiProject Mathematics"
          },
          "subclass_of": [
            {
              "id": "Q12718609",
              "label": "statistical method"
            },
            {
              "id": "Q938438",
              "label": "statistical inference"
            }
          ],
          "P12385": "inferencia-bayesiana",
          "commons_category": "Bayesian inference",
          "P1269": "Q812534",
          "P13591": "concept/89628c4b-4062-4a41-9920-860f80a2eb33",
          "P1036": "519.542"
        }
      }
    },
    {
      "name": "Imitation learning",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Imitation_learning",
      "relevance": "The problem of learning from expert demonstrations is central to the inverse reinforcement learning framework presented.",
      "wikidata": {
        "id": "Q124742024",
        "label": "imitation learning",
        "description": "machine learning technique where agents learn from demonstrations",
        "aliases": [
          "behavior cloning",
          "behaviour cloning",
          "learning from demonstration"
        ],
        "claims": {
          "subclass_of": {
            "id": "Q7353390",
            "label": "robot learning"
          },
          "instance_of": "Q117348143",
          "P1269": "Q170978",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    }
  ]
}