{
  "paper_type": "survey",
  "triples": [
    {
      "name": "Deep Reinforcement Learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Core topic of the survey covering integration of deep learning with RL for end-to-end decision-making",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_reinforcement_learning",
      "wikidata": {
        "id": "Q65079156",
        "label": "deep reinforcement learning",
        "description": "techniques combining deep learning and reinforcement learning principles to create efficient machine learning algorithms",
        "aliases": [
          "DRL"
        ],
        "claims": {
          "google_kg_id": [
            "/g/11h0mpm7vy",
            "/g/11f6y3p_tx"
          ],
          "subclass_of": [
            {
              "id": "Q830687",
              "label": "reinforcement learning"
            },
            {
              "id": "Q197536",
              "label": "deep learning"
            }
          ],
          "P10376": "computer-science/deep-reinforcement-learning"
        }
      }
    },
    {
      "name": "Deep Learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Feature representation technique that DRL leverages for processing high-dimensional inputs",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_learning",
      "wikidata": {
        "id": "Q197536",
        "label": "deep learning",
        "description": "branch of machine learning",
        "aliases": [
          "DL",
          "deep machine learning",
          "hierarchical learning",
          "deep structured learning"
        ],
        "claims": {
          "freebase_id": "/m/0h1fn8h",
          "P61": [
            {
              "id": "Q3571662",
              "label": "Yann Le Cun"
            },
            {
              "id": "Q92894",
              "label": "Geoffrey Hinton"
            }
          ],
          "topic_main_category": {
            "id": "Q24070291",
            "label": "Category:Deep learning"
          },
          "quora_topic_id": "Deep-Learning",
          "P3219": "apprentissage-profond-deep-learning",
          "subclass_of": {
            "id": "Q111862379",
            "label": "machine learning method"
          },
          "commons_category": "Deep learning",
          "P4342": [
            "dyplæring",
            "dyp_læring"
          ],
          "P6363": "http://data.thenextweb.com/tnw/entity/deep_learning",
          "use": {
            "id": "Q11660",
            "label": "artificial intelligence"
          },
          "P3553": "19813032",
          "mesh_id": "D000077321",
          "mesh_tree_code": [
            "G17.035.250.500.250",
            "G17.485.500",
            "L01.224.050.375.530.250",
            "L01.224.050.375.605.500"
          ],
          "mag_id": "108583219",
          "P3984": "deeplearning",
          "P7502": "Deep_learning-PE5E9Y",
          "P9100": [
            "deep-learning",
            "deep-learning-tutorial",
            "deeplearning"
          ],
          "P8529": "461103",
          "P9526": "Deep_Learning",
          "image": "Deep Learning.jpg",
          "P6802": "Computer vision sample in Simón Bolivar Avenue, Quito.jpg",
          "openalex_id": [
            "C108583219",
            "C2984842247"
          ],
          "P2347": "39324",
          "openalex_topic_id": [
            "216836",
            "221130"
          ],
          "P691": "ph1042930",
          "P11408": "ディープラーニング",
          "P8687": "+95159",
          "P5844": "deep-learning_(Neologismi)",
          "P2892": "C4704761",
          "P11196": "深度学习",
          "P12086": "Deep_learning",
          "P8189": "987011038167805171",
          "loc_id": "sh2021006947",
          "P1368": "000350792",
          "P9346": "deep-learning",
          "P3911": "30476-3",
          "P6900": "ディープラーニング",
          "P13397": "deep+learning",
          "P508": "78027",
          "P268": "17706295v",
          "gnd_id": "1135597375",
          "P3235": "deep-learning",
          "stack_exchange_tag": [
            "https://ai.stackexchange.com/tags/deep-learning",
            "https://or.stackexchange.com/tags/deep-learning",
            "https://stats.stackexchange.com/tags/deep-learning"
          ],
          "P13591": "concept/21bbd7b7-62b1-4bd8-844d-00f4bc0ccd62",
          "P1036": "006.31",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Reinforcement Learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Fundamental decision-making paradigm that DRL combines with deep learning",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": "Q2539",
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": "Q2539",
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            {
              "id": "Q111862379",
              "label": "machine learning method"
            },
            {
              "id": "Q130609847",
              "label": "learning approach"
            }
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Policy Gradient Method",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Policy-based DRL algorithm class that directly learns policy functions mentioned in the paper",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Policy_gradient_method",
      "wikidata": {
        "id": "Q113840014",
        "label": "policy-gradient method",
        "description": "class of reinforcement learning algorithms",
        "aliases": [
          "policy gradient method",
          "policy gradient"
        ],
        "claims": {
          "subclass_of": {
            "id": "Q830687",
            "label": "reinforcement learning"
          },
          "P9526": "Policy_gradient_methods",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Q-learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Foundational value-based RL algorithm that DRL extends with neural networks",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Q-learning",
      "wikidata": {
        "id": "Q2664563",
        "label": "Q-learning",
        "description": "model-free reinforcement learning algorithm",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/04pvn7",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/q-learning",
            "https://ai.stackexchange.com/tags/q-learning"
          ],
          "quora_topic_id": "Q-learning",
          "P1269": {
            "id": "Q830687",
            "label": "reinforcement learning"
          },
          "mag_id": "188116033",
          "instance_of": {
            "id": "Q8366",
            "label": "algorithm"
          },
          "subclass_of": {
            "id": "Q63788448",
            "label": "model-free reinforcement learning"
          },
          "P2179": "10010329",
          "openalex_id": "C188116033",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Hierarchical Control System",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Framework for hierarchical reinforcement learning mentioned as a key research subdomain in DRL",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Hierarchical_control_system",
      "wikidata": {
        "id": "Q17029359",
        "label": "Hierarchical control system",
        "description": "layered model for component organization in software and robotics",
        "aliases": [],
        "claims": {
          "mag_id": "124527596",
          "freebase_id": "/m/03hp81k",
          "openalex_id": "C124527596",
          "subclass_of": {
            "id": "Q959968",
            "label": "control system"
          },
          "openalex_topic_id": "185702"
        }
      }
    },
    {
      "name": "Multi-agent Learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Multiagent reinforcement learning research domain mentioned as a major DRL subdomain",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Multi-agent_learning",
      "wikidata": {
        "id": "Q85786957",
        "label": "Multi-agent reinforcement learning",
        "description": "sub-field of reinforcement learning",
        "aliases": [
          "multi-agent learning",
          "MARL"
        ],
        "claims": {
          "google_kg_id": "/g/11fpjwxwbb",
          "subclass_of": {
            "id": "Q830687",
            "label": "reinforcement learning"
          }
        }
      }
    },
    {
      "name": "Imitation Learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Learning from demonstrations paradigm developed alongside DRL as a related subfield",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Imitation_learning",
      "wikidata": {
        "id": "Q124742024",
        "label": "imitation learning",
        "description": "machine learning technique where agents learn from demonstrations",
        "aliases": [
          "behavior cloning",
          "behaviour cloning",
          "learning from demonstration"
        ],
        "claims": {
          "subclass_of": "Q7353390",
          "instance_of": "Q117348143",
          "P1269": "Q170978",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Principle of Maximum Entropy",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Theoretical foundation for maximum entropy-based DRL algorithms discussed in the survey",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Principle_of_maximum_entropy",
      "wikidata": {
        "id": "Q1417473",
        "label": "principle of maximum entropy",
        "description": "principle in Bayesian statistics",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/01cnn4",
          "instance_of": "Q211364",
          "P61": "Q711210",
          "P575": "1957-00-00",
          "P3827": "maximum-entropy-method",
          "loc_id": "sh91000157",
          "mag_id": "9679016",
          "part_of": "Q11473",
          "openalex_id": [
            "C127233936",
            "C9679016",
            "C2987321033"
          ],
          "openalex_topic_id": [
            "237602",
            "127598"
          ],
          "P8189": "987007544252505171",
          "P4839": "Entity[\"PhysicalEffect\", \"PrincipleOfMaximumEntropy\"]",
          "P13591": "concept/ef80008c-29e7-4edf-972e-3789f81c1ab4"
        }
      }
    },
    {
      "name": "Markov Decision Process",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Theoretical framework underlying reinforcement learning and decision-making in DRL",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Markov_decision_process",
      "wikidata": {
        "id": "Q176789",
        "label": "Markov decision process",
        "description": "mathematical model for sequential decision making under uncertainty",
        "aliases": [
          "MDP",
          "MDPs"
        ],
        "claims": {
          "P138": "Q176659",
          "freebase_id": "/m/048gl8",
          "P1051": "7713",
          "P4969": "Q176814",
          "mag_id": "106189395",
          "openalex_id": "C106189395",
          "subclass_of": [
            "Q1331926",
            {
              "id": "Q176737",
              "label": "stochastic process"
            }
          ],
          "openalex_topic_id": "56113",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    }
  ]
}