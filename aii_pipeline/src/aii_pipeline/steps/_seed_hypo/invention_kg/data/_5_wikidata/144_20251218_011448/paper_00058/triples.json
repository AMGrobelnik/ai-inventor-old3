{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Monte Carlo method",
      "relation": "proposes",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Monte_Carlo_method",
      "relevance": "The paper proposes a Monte-Carlo simulation algorithm as the core technique for real-time policy improvement.",
      "wikidata": {
        "id": "Q232207",
        "label": "Monte Carlo method",
        "description": "broad class of computational algorithms using random sampling to obtain numerical results",
        "aliases": [
          "MC method",
          "Monte Carlo experiment",
          "Monte Carlo simulation",
          "Monte Carlo algorithm"
        ],
        "claims": {
          "commons_category": "Monte Carlo method",
          "P508": "32258",
          "topic_main_category": {
            "id": "Q9210903",
            "label": "Category:Monte Carlo methods"
          },
          "P349": "00567842",
          "freebase_id": "/m/0fjvb",
          "subclass_of": [
            {
              "id": "Q583461",
              "label": "randomized algorithm"
            },
            "Q45045"
          ],
          "P1051": "7198",
          "P138": "Q1779905",
          "P61": [
            "Q8753",
            "Q234357",
            {
              "id": "Q17455",
              "label": "John von Neumann"
            }
          ],
          "gnd_id": "4240945-7",
          "instance_of": {
            "id": "Q583461",
            "label": "randomized algorithm"
          },
          "britannica_id": "science/Monte-Carlo-method",
          "quora_topic_id": "Monte-Carlo-Techniques",
          "P3827": "monte-carlo-methods",
          "mesh_id": "D009010",
          "P2812": "MonteCarloMethod",
          "loc_id": "sh85087032",
          "P2924": "2228629",
          "described_by_source": "Q124737635",
          "P1296": "0043727",
          "mesh_tree_code": [
            "E05.318.740.525",
            "L01.906.394.422",
            "N05.715.360.750.540",
            "N06.850.520.830.525"
          ],
          "P4732": "MT07072",
          "mag_id": "19499675",
          "P2347": "6361",
          "different_from": "Q15238499",
          "P8408": "MonteCarloMethod",
          "P9100": "monte-carlo-simulation",
          "image": "Pi 30K.gif",
          "P8189": "987007543534905171",
          "openalex_id": "C19499675",
          "P8313": "Monte_Carlo-metoder",
          "P4342": "Monte_Carlo-metode",
          "P691": "ph122780",
          "openalex_topic_id": [
            "76305",
            "321898",
            "234677",
            "154023"
          ],
          "P3911": "15267-6",
          "stack_exchange_tag": [
            "https://ai.stackexchange.com/tags/monte-carlo-methods",
            "https://computergraphics.stackexchange.com/tags/monte-carlo"
          ],
          "P3222": "monte-carlo-metoder",
          "P2892": "C0026507",
          "P6104": {
            "id": "Q8487137",
            "label": "WikiProject Mathematics"
          },
          "P6564": "monte-carlo",
          "P12385": "metode-de-montecarlo",
          "P1036": "518.282",
          "P13591": "concept/be660e7d-7744-46b7-9240-80a1964be733"
        }
      }
    },
    {
      "name": "Reinforcement learning",
      "relation": "proposes",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "relevance": "The paper contributes policy improvement methodology within the reinforcement learning framework.",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            "Q111862379",
            "Q130609847"
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Backgammon",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Backgammon",
      "relevance": "Backgammon is the primary application domain for demonstrating the effectiveness of the Monte-Carlo algorithm.",
      "wikidata": {
        "id": "Q11411",
        "label": "backgammon",
        "description": "one of the oldest board games for two players",
        "aliases": [],
        "claims": {
          "commons_category": "Backgammon",
          "P508": "16757",
          "gnd_id": "4069063-5",
          "topic_main_category": "Q8285557",
          "P349": "00577370",
          "freebase_id": "/m/01d30",
          "image": "Backgammon lg.jpg",
          "P2339": "2397",
          "subclass_of": {
            "id": "Q1188693",
            "label": "mind sport"
          },
          "quora_topic_id": "Backgammon",
          "P1014": "300222747",
          "P3827": "backgammon",
          "P3222": "backgammon",
          "P2812": "Backgammon",
          "P3219": "backgammon",
          "babelnet_id": "00007779n",
          "practiced_by": {
            "id": "Q23929009",
            "label": "backgammon player"
          },
          "P5008": [
            {
              "id": "Q5460604",
              "label": "Wikipedia:List of articles all languages should have"
            },
            {
              "id": "Q6173448",
              "label": "Wikipedia:Vital articles/Level/4"
            }
          ],
          "britannica_id": "topic/backgammon",
          "instance_of": [
            "Q131436",
            "Q1515156",
            {
              "id": "Q17351672",
              "label": "social game"
            },
            {
              "id": "Q47728",
              "label": "hobby"
            }
          ],
          "described_by_source": [
            {
              "id": "Q602358",
              "label": "Brockhaus and Efron Encyclopedic Dictionary"
            },
            {
              "id": "Q19219752",
              "label": "Meyers Konversations-Lexikon, 4th edition (1885–1890)"
            },
            "Q867541"
          ],
          "P989": "Backgammon.ogg",
          "P1245": "858195",
          "P8408": "Backgammon",
          "P8519": "66369",
          "P4342": "backgammon",
          "use": [
            "Q173799",
            "Q349",
            {
              "id": "Q841654",
              "label": "competition"
            }
          ],
          "loc_id": "sh85010798",
          "P1872": "+2",
          "P1873": "+2",
          "P2899": "+5",
          "P8514": "gamao  vhdbj cgpñbebewoakn n gjkeola,sbx ,cvmb",
          "P268": "11938367h",
          "P8189": "987007284650805171",
          "P8313": "backgammon",
          "P8814": "00503833-n",
          "P7749": "14218",
          "P5160": "tgm000705",
          "coincident_with": "Q968853",
          "P3984": "backgammon",
          "P6104": {
            "id": "Q8487137",
            "label": "WikiProject Mathematics"
          },
          "P2924": "2249090",
          "P11137": "backgammon",
          "P12596": "21436",
          "P8309": "18-164161",
          "P13397": "Backgammon",
          "P13591": "concept/536912f4-3185-4272-b056-44ac70e0f680",
          "P1036": "795.15"
        }
      }
    },
    {
      "name": "TD-Gammon",
      "relation": "uses",
      "entity_type": "artifact",
      "wikipedia_url": "https://en.wikipedia.org/wiki/TD-Gammon",
      "relevance": "TD-Gammon is a strong baseline neural network model used as an initial policy for comparison and improvement.",
      "wikidata": {
        "id": "Q7669824",
        "label": "TD-Gammon",
        "description": "is a computer backgammon program developed in 1992",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/0b6m8hy",
          "P9100": "td-gammon"
        }
      }
    },
    {
      "name": "Neural network",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
      "relevance": "The paper applies Monte-Carlo search to improve policies based on multi-layer neural networks like TD-Gammon.",
      "wikidata": {
        "id": "Q192776",
        "label": "artificial neural network",
        "description": "computational model used in machine learning, based on connected, hierarchical functions",
        "aliases": [
          "ANN",
          "neural network",
          "connectionist system",
          "connectionist systems",
          "deep nets",
          "Simulated Neural Network",
          "Static Neural Network",
          "SNN",
          "Synergetic Neural Network",
          "Neural Networks, Computer",
          "neural net",
          "artificial neural networks"
        ],
        "claims": {
          "P349": "01165604",
          "commons_category": "Artificial neural networks",
          "P1014": "300389897",
          "topic_main_category": {
            "id": "Q9246857",
            "label": "Category:Artificial neural networks"
          },
          "P935": "Artificial neural network",
          "gnd_id": "4226127-2",
          "subclass_of": [
            "Q11660",
            {
              "id": "Q2539",
              "label": "machine learning"
            },
            {
              "id": "Q12811862",
              "label": "neural network"
            },
            "Q5282087"
          ],
          "mesh_id": "D016571",
          "freebase_id": "/m/05dhw",
          "quora_topic_id": "Artificial-Neural-Networks-ANNs",
          "P2924": [
            "4114009",
            "2256451"
          ],
          "P3827": "artificial-neural-networks",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/neural-network",
            "https://stats.stackexchange.com/tags/neural-networks",
            "https://cs.stackexchange.com/tags/neural-networks",
            "https://ai.stackexchange.com/tags/neural-networks"
          ],
          "babelnet_id": "00057388n",
          "P4732": "AT06947",
          "P3219": "reseaux-de-neurones-formels",
          "P4342": "nevralt_nettverk",
          "P5398": "000000120",
          "loc_id": "sh90001937",
          "P6564": "artificial-neural-network",
          "P443": "LL-Q150 (fra)-0x010C-réseau de neurones artificiels.wav",
          "P1245": "1706096",
          "mag_id": "50644808",
          "image": "Neural network.svg",
          "P1552": {
            "id": "Q7860946",
            "label": "types of artificial neural networks"
          },
          "P8408": "ArtificialNeuralNetwork",
          "mesh_tree_code": [
            "G17.485",
            "L01.224.050.375.605"
          ],
          "P7502": "Artificial_neural_network-YZ9",
          "P9100": [
            "neural-network",
            "artificial-neural-network"
          ],
          "P9545": "226614",
          "P9935": "reti-neurali-e-robotica",
          "P2004": "12606",
          "P8189": "987007551192405171",
          "P8529": "461104",
          "openalex_id": "C50644808",
          "has_parts": [
            {
              "id": "Q110857102",
              "label": "neuron layer"
            },
            {
              "id": "Q1036748",
              "label": "loss function"
            },
            {
              "id": "Q110857125",
              "label": "optimizer"
            },
            "Q177058",
            "Q101517027"
          ],
          "openalex_topic_id": [
            "18651",
            "509993",
            "238094",
            "88631"
          ],
          "P1557": {
            "id": "Q43283",
            "label": "biological neural network"
          },
          "uses": {
            "id": "Q4677469",
            "label": "activation function"
          },
          "P691": "ph115443",
          "P6262": "apple:Artificial_neural_network",
          "P3847": "neural_networks_(computer_science)",
          "P1269": [
            "Q11660",
            {
              "id": "Q2539",
              "label": "machine learning"
            }
          ],
          "P11514": "neironnye-seti-e734b3",
          "P10376": [
            "computer-science/artificial-neural-networks",
            "computer-science/artificial-neural-network",
            "biochemistry-genetics-and-molecular-biology/artificial-neural-network",
            "veterinary-science-and-veterinary-medicine/artificial-neural-network",
            "physics-and-astronomy/artificial-neural-network",
            "nursing-and-health-professions/artificial-neural-network",
            "neuroscience/artificial-neural-network",
            "mathematics/artificial-neural-network",
            "immunology-and-microbiology/artificial-neural-network",
            "engineering/artificial-neural-network",
            "earth-and-planetary-sciences/artificial-neural-network"
          ],
          "P2892": "C0870951",
          "P7305": "3946887",
          "instance_of": {
            "id": "Q120281892",
            "label": "type of statistical model"
          },
          "P3911": "19808-6",
          "P5019": "neuronale-netze-kunstliche-intelligenz",
          "P1368": "000053170",
          "P5437": "c_65b9cd79",
          "P8885": "인공신경망",
          "P12946": "artificial+neural+network",
          "P7276": "UM%C4%9AL%C3%81%20NEURONOV%C3%81%20S%C3%8D%C5%A4",
          "P6900": "ニューラルネットワーク",
          "P3365": "rete-neurale",
          "P9621": "rete-neurale",
          "P10037": "reti-neurali-e-vita-artificiale",
          "P9941": "reti-neurali",
          "P13411": "Q153",
          "P989": "En-Neural network.ogg",
          "P13591": "concept/6faed690-ea28-4208-a446-ad355ec1cb8e",
          "P10380": "network-models"
        }
      }
    },
    {
      "name": "Adaptive control",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Adaptive_control",
      "relevance": "The paper frames policy improvement as an adaptive control problem where the controller adapts to improve performance.",
      "wikidata": {
        "id": "Q235781",
        "label": "adaptive control",
        "description": "control method used by a controller that must adapt to a system with parameters which vary or are initially uncertain",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/06fn9d",
          "topic_main_category": "Q9423742",
          "quora_topic_id": "Adaptive-Control",
          "P3827": "adaptive-control",
          "britannica_id": "technology/adaptive-control",
          "subclass_of": [
            "Q6501221",
            {
              "id": "Q115135908",
              "label": "nonlinear control system"
            }
          ],
          "instance_of": {
            "id": "Q1799072",
            "label": "method"
          },
          "mag_id": "107464732",
          "P3553": "20031173",
          "openalex_id": "C107464732"
        }
      }
    },
    {
      "name": "Expected value",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Expected_value",
      "relevance": "The algorithm measures the long-term expected reward of actions, a fundamental concept in reinforcement learning.",
      "wikidata": {
        "id": "Q200125",
        "label": "expectation",
        "description": "long-run average value of a random variable",
        "aliases": [
          "mathematical expectation",
          "first moment",
          "expected value",
          "expectation value"
        ],
        "claims": {
          "freebase_id": "/m/02mnh",
          "described_by_source": [
            {
              "id": "Q20078554",
              "label": "Great Soviet Encyclopedia (1926–1947)"
            },
            "Q111973641",
            {
              "id": "Q123625363",
              "label": "Armenian Soviet Encyclopedia, vol. 7"
            }
          ],
          "gnd_id": "4152930-3",
          "P3827": "expected-values",
          "subclass_of": "Q19033",
          "britannica_id": "topic/expected-value",
          "P2924": "2192699",
          "mag_id": "141042865",
          "P4613": "67449",
          "P1269": {
            "id": "Q1362683",
            "label": "expectation"
          },
          "P8855": "103-08-10",
          "P3553": "19967504",
          "P6802": "Largenumbers.svg",
          "P7305": "3949733",
          "openalex_id": "C141042865",
          "P2812": "ExpectationValue",
          "P2534": [
            "E[g(X)] = \\int\\limits_{\\Omega} g(X) \\mathrm{d} P",
            "E[g(X)] = \\int\\limits_{\\mathbb{R}^k} g(x) \\mathrm{d} F(x)"
          ],
          "P7235": [
            "E[g(X)]",
            "g",
            "X",
            "\\Omega",
            "P",
            "\\mathbb{R}",
            "F(x)"
          ],
          "different_from": {
            "id": "Q112594430",
            "label": "mean"
          },
          "P4215": "expectation value",
          "P5008": {
            "id": "Q6173448",
            "label": "Wikipedia:Vital articles/Level/4"
          },
          "P7973": [
            "E(\\cdot)",
            "E[\\cdot]"
          ],
          "P11514": "matematicheskoe-ozhidanie-5168ec",
          "P6104": {
            "id": "Q8487137",
            "label": "WikiProject Mathematics"
          },
          "P6564": "expected-value",
          "P3911": "29919-5",
          "P12457": "Q6803556",
          "P10": "Erwartungswert, Varianz und Standardabweichung - diskrete Zufallsgröße.webm"
        }
      }
    },
    {
      "name": "IBM Scalable POWERparallel",
      "relation": "uses",
      "entity_type": "tool",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Scalable_POWERparallel",
      "relevance": "The algorithm was implemented on IBM SP1 and SP2 parallel supercomputers for efficient computation.",
      "wikidata": {
        "id": "Q3788443",
        "label": "IBM Scalable POWERparallel",
        "description": "series of supercomputers by IBM",
        "aliases": [],
        "claims": {
          "P176": {
            "id": "Q37156",
            "label": "IBM"
          },
          "instance_of": {
            "id": "Q811701",
            "label": "model series"
          },
          "P571": "1993-02-01",
          "freebase_id": "/m/0b3jyv",
          "commons_category": "IBM RS/6000 SP",
          "subclass_of": {
            "id": "Q121117",
            "label": "supercomputer"
          }
        }
      }
    }
  ]
}