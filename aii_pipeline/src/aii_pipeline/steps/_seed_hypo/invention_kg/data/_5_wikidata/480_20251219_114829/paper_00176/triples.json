{
  "paper_type": "survey",
  "triples": [
    {
      "name": "Sequential decision making",
      "relation": "uses",
      "entity_type": "task",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Sequential_decision_making",
      "relevance": "The paper's foundation—it covers how to optimize sequential decision making through model-based RL.",
      "wikidata": {
        "id": "Q55643366",
        "label": "Sequential decision making",
        "description": "Concept in control theory",
        "aliases": [],
        "claims": {
          "britannica_id": "topic/sequential-decision-making",
          "google_kg_id": "/g/11g0mcv8hh",
          "P3911": "15475-6"
        }
      }
    },
    {
      "name": "Markov decision process",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Markov_decision_process",
      "relevance": "The primary formalism used to represent the sequential decision making problems that the survey addresses.",
      "wikidata": {
        "id": "Q176789",
        "label": "Markov decision process",
        "description": "mathematical model for sequential decision making under uncertainty",
        "aliases": [
          "MDP",
          "MDPs"
        ],
        "claims": {
          "P138": "Q176659",
          "freebase_id": "/m/048gl8",
          "P1051": "7713",
          "P4969": "Q176814",
          "mag_id": "106189395",
          "openalex_id": "C106189395",
          "subclass_of": [
            "Q1331926",
            {
              "id": "Q176737",
              "label": "stochastic process"
            }
          ],
          "openalex_topic_id": "56113",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Reinforcement learning",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "relevance": "One of the two key approaches that model-based RL integrates alongside planning.",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": "Q2539",
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": "Q2539",
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            {
              "id": "Q111862379",
              "label": "machine learning method"
            },
            {
              "id": "Q130609847",
              "label": "learning approach"
            }
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Automated planning and scheduling",
      "relation": "uses",
      "entity_type": "method",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling",
      "relevance": "The other key approach that model-based RL integrates with reinforcement learning for optimization.",
      "wikidata": {
        "id": "Q2631895",
        "label": "automated planning and scheduling",
        "description": "branch of artificial intelligence that concerns the realization of strategies or action sequences",
        "aliases": [
          "AI planning"
        ],
        "claims": {
          "topic_main_category": {
            "id": "Q8279954",
            "label": "Category:Automated planning and scheduling"
          },
          "freebase_id": "/m/056l8b",
          "mag_id": "114073186",
          "use": [
            {
              "id": "Q2271896",
              "label": "scheduling"
            },
            {
              "id": "Q309100",
              "label": "planning"
            }
          ],
          "instance_of": "Q4485156",
          "P8529": "460209",
          "subclass_of": {
            "id": "Q11660",
            "label": "artificial intelligence"
          },
          "openalex_id": "C114073186"
        }
      }
    },
    {
      "name": "Hierarchical control system",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Hierarchical_control_system",
      "relevance": "The survey draws connections to hierarchical RL which uses hierarchical abstraction for decision making.",
      "wikidata": {
        "id": "Q17029359",
        "label": "Hierarchical control system",
        "description": "layered model for component organization in software and robotics",
        "aliases": [],
        "claims": {
          "mag_id": "124527596",
          "freebase_id": "/m/03hp81k",
          "openalex_id": "C124527596",
          "subclass_of": {
            "id": "Q959968",
            "label": "control system"
          },
          "openalex_topic_id": "185702"
        }
      }
    },
    {
      "name": "Transfer learning",
      "relation": "uses",
      "entity_type": "concept",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transfer_learning",
      "relevance": "The survey covers connections to transfer learning, another related RL field mentioned explicitly.",
      "wikidata": {
        "id": "Q6027324",
        "label": "transfer learning",
        "description": "research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem",
        "aliases": [
          "inductive transfer"
        ],
        "claims": {
          "subclass_of": "Q2539",
          "quora_topic_id": "Transfer-Learning",
          "part_of": "Q2539",
          "mag_id": "77075516",
          "freebase_id": "/m/0b6vrv",
          "instance_of": {
            "id": "Q28643",
            "label": "paradigm"
          },
          "uses": {
            "id": "Q6015447",
            "label": "incremental computation"
          },
          "P9100": "transfer-learning",
          "openalex_id": "C77075516",
          "schematic": "Transfer learning.svg",
          "different_from": "Q1820378",
          "mesh_id": "D000098410",
          "mesh_tree_code": [
            "G17.035.250.500.625",
            "L01.224.050.375.530.625"
          ],
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    }
  ]
}