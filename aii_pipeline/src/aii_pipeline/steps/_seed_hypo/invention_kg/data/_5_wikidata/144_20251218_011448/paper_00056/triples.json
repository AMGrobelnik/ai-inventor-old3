{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Reinforcement learning",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The paper builds on reinforcement learning as the foundational ML paradigm for learning from interaction with environments.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            "Q111862379",
            "Q130609847"
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Deep reinforcement learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "The paper addresses challenges in deep reinforcement learning algorithms for offline learning from fixed batch data.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_reinforcement_learning",
      "wikidata": {
        "id": "Q65079156",
        "label": "deep reinforcement learning",
        "description": "techniques combining deep learning and reinforcement learning principles to create efficient machine learning algorithms",
        "aliases": [
          "DRL"
        ],
        "claims": {
          "google_kg_id": [
            "/g/11h0mpm7vy",
            "/g/11f6y3p_tx"
          ],
          "subclass_of": [
            {
              "id": "Q830687",
              "label": "reinforcement learning"
            },
            "Q197536"
          ],
          "P10376": "computer-science/deep-reinforcement-learning"
        }
      }
    },
    {
      "name": "Q-learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "DQN is a deep learning variant of Q-learning, which the paper demonstrates has extrapolation issues in batch settings.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Q-learning",
      "wikidata": {
        "id": "Q2664563",
        "label": "Q-learning",
        "description": "model-free reinforcement learning algorithm",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/04pvn7",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/q-learning",
            "https://ai.stackexchange.com/tags/q-learning"
          ],
          "quora_topic_id": "Q-learning",
          "P1269": {
            "id": "Q830687",
            "label": "reinforcement learning"
          },
          "mag_id": "188116033",
          "instance_of": "Q8366",
          "subclass_of": "Q63788448",
          "P2179": "10010329",
          "openalex_id": "C188116033",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "DQN",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "The paper identifies DQN as an example of off-policy algorithm that fails when learning from uncorrelated data.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/DQN",
      "wikidata": {
        "id": "Q15948162",
        "label": "DQN",
        "description": "Wikimedia disambiguation page",
        "aliases": [],
        "claims": {
          "instance_of": "Q4167410"
        }
      }
    },
    {
      "name": "Actor-critic algorithm",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "DDPG is an actor-critic method that the paper demonstrates also fails in batch-constrained settings.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Actor-critic_algorithm",
      "wikidata": {
        "id": "Q131936605",
        "label": "Actor-critic algorithm",
        "description": "reinforcement learning algorithms that combine policy and value estimation",
        "aliases": [],
        "claims": {
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Offline learning",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The core problem the paper addresses is learning from fixed, offline batch data without further environment interaction.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Offline_learning",
      "wikidata": {
        "id": "Q7079636",
        "label": "offline machine learning",
        "description": "method of machine learning",
        "aliases": [
          "batch learning",
          "cumulated modification learning",
          "epochal learning",
          "block learning"
        ],
        "claims": {
          "subclass_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "opposite_of": {
            "id": "Q7094097",
            "label": "online machine learning"
          },
          "mag_id": "2780490138",
          "freebase_id": "/m/02qnykr",
          "openalex_id": "C2780490138"
        }
      }
    },
    {
      "name": "Exploration–exploitation dilemma",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The paper's batch-constrained approach addresses exploration issues by constraining actions to stay near the data distribution.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Exploration%E2%80%93exploitation_dilemma",
      "wikidata": {
        "id": "Q119840411",
        "label": "exploration–exploitation dilemma",
        "description": "decision-making tradeoff between relying on current best estimates and seeking more information",
        "aliases": [
          "exploration-exploitation dilemma",
          "exploration–exploitation tradeoff",
          "exploration–exploitation trade-off",
          "exploration vs. exploitation",
          "exploration versus exploitation"
        ],
        "claims": {
          "subclass_of": {
            "id": "Q638123",
            "label": "trade-off"
          },
          "P1269": [
            {
              "id": "Q177571",
              "label": "decision theory"
            },
            "Q141495"
          ],
          "uses": {
            "id": "Q4929239",
            "label": "data collection"
          },
          "instance_of": "Q29028649"
        }
      }
    },
    {
      "name": "Batch learning",
      "entity_type": "method",
      "relation": "proposes",
      "relevance": "The paper proposes batch-constrained reinforcement learning, a novel class of algorithms for learning from fixed batch data without environment interaction.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Batch_learning",
      "wikidata": {
        "id": "Q7094097",
        "label": "online machine learning",
        "description": "a method where a model is trained incrementally on data as it becomes available, in contrast to batch learning where the entire dataset is used at once",
        "aliases": [
          "incremental learning",
          "adaptive learning",
          "online learning",
          "Real-Time Learning"
        ],
        "claims": {
          "subclass_of": [
            {
              "id": "Q2539",
              "label": "machine learning"
            },
            "Q28324931"
          ],
          "opposite_of": "Q7079636",
          "P2534": "I[f] = \\mathbb{E}[V(f(x), y)] = \\int V(f(x), y)\\,dp(x, y)",
          "part_of": {
            "id": "Q2539",
            "label": "machine learning"
          },
          "mag_id": "115903097",
          "freebase_id": "/m/04q9r7w",
          "openalex_id": "C115903097",
          "P6104": {
            "id": "Q8487137",
            "label": "WikiProject Mathematics"
          }
        }
      }
    }
  ]
}