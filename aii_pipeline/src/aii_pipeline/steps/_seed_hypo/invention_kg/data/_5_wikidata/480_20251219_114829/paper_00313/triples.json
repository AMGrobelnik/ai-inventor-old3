{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Speech synthesis",
      "entity_type": "task",
      "relation": "proposes",
      "relevance": "Vall-E proposes a new approach to speech synthesis using neural codec language models.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Speech_synthesis",
      "wikidata": {
        "id": "Q16346",
        "label": "speech synthesis",
        "description": "artificial production of human speech",
        "aliases": [
          "text-to-speech",
          "computer generated speech",
          "mariam"
        ],
        "claims": {
          "commons_category": "Speech synthesis",
          "topic_main_category": "Q7484888",
          "P349": "00575464",
          "freebase_id": "/m/0brhx",
          "stack_exchange_tag": "https://stackoverflow.com/tags/speech-synthesis",
          "P1051": "13788",
          "quora_topic_id": "Speech-Synthesis",
          "P3827": "speech-synthesis",
          "britannica_id": [
            "topic/speech-synthesis",
            "topic/speech-synthesizer"
          ],
          "babelnet_id": "03172404n",
          "P6009": "3647",
          "P2579": {
            "id": "Q30642",
            "label": "natural language processing"
          },
          "P7033": "scot/15597",
          "P989": "Nl-Spraaksynthese-article.ogg",
          "P7502": "Speech_synthesis",
          "mag_id": "14999030",
          "P6900": "音声合成",
          "subclass_of": {
            "id": "Q7554316",
            "label": "sound synthesis"
          },
          "P3553": "19866187",
          "P51": [
            "Amiga speech synthesis.flac",
            "C64 Software Automatic Mouth demo.flac",
            "DECtalk demo.flac",
            "Emergency broadcast in Mihama town 180918.opus",
            "Vocoder demo.ogg",
            "Texas Instruments TI-99 4A speech demo.flac",
            "MacinTalk Alex.ogg",
            "MacinTalk 2 demo.flac",
            "MacinTalk 1 demo.flac",
            "Larynx-HiFi-GAN speech sample.wav",
            "Fidelity Chess Challenger Voice speech output.flac",
            "JärDa-utrop.ogg",
            "Festival Speech Synthesis System.ogg",
            "Emergency broadcast in Uenohara city 180902.opus"
          ],
          "P8529": "460211",
          "openalex_id": "C14999030",
          "P2347": "28546",
          "P8313": "talesyntese",
          "P1330": "b0f83029-6d38-4f6f-bd30-db44e427f497",
          "openalex_topic_id": [
            "121711",
            "199539"
          ],
          "P691": "ph351275",
          "P5247": "3015-9658",
          "P5008": {
            "id": "Q6173448",
            "label": "Wikipedia:Vital articles/Level/4"
          },
          "P508": "74065",
          "google_kg_id": "/g/12pgcqvh9",
          "P1617": "2f32f60b-6fbd-433d-bb19-931e99cdeb72",
          "P12328": "Q52946",
          "P8189": "987007565841305171",
          "P11129": "Sprachausgabe",
          "P12946": "speech+synthesis",
          "P9497": "2445",
          "topic_maintained_by": {
            "id": "Q6373966",
            "label": "Template:Speech synthesis"
          },
          "P11408": "音声合成"
        }
      }
    },
    {
      "name": "Language model",
      "entity_type": "method",
      "relation": "proposes",
      "relevance": "The paper proposes using language modeling as the core technique for TTS instead of continuous signal regression.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Language_model",
      "wikidata": {
        "id": "Q3621696",
        "label": "language model",
        "description": "probabilistic model of a natural or formal language, or generally of elements of signal sequences",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/065lv0",
          "mag_id": "137293760",
          "subclass_of": "Q3284399",
          "P1269": {
            "id": "Q30642",
            "label": "natural language processing"
          },
          "P8408": "LanguageModeling",
          "openalex_id": "C137293760",
          "P10407": "923-2",
          "use": "Q96407327",
          "openalex_topic_id": "184201",
          "topic_main_category": "Q16500316",
          "P12086": "Taalmodel",
          "P8309": "18-332728",
          "P1368": "000355288",
          "P13397": "language+model",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "In-context learning (natural language processing)",
      "entity_type": "concept",
      "relation": "proposes",
      "relevance": "Vall-E demonstrates emergent in-context learning capabilities that allow synthesis with only a 3-second acoustic prompt.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/In-context_learning_(natural_language_processing)",
      "wikidata": {
        "id": "Q108941486",
        "label": "prompt engineering",
        "description": "creation or optimization of a prompt to be given to an artificial intelligence model",
        "aliases": [
          "prompt-based learning",
          "AI prompt engineering"
        ],
        "claims": {
          "subclass_of": [
            "Q110484020",
            {
              "id": "Q80006",
              "label": "computer programming"
            }
          ],
          "instance_of": [
            {
              "id": "Q2695280",
              "label": "technique"
            },
            {
              "id": "Q627436",
              "label": "field of work"
            }
          ],
          "P1269": {
            "id": "Q11660",
            "label": "artificial intelligence"
          },
          "use": [
            "Q65066631",
            "Q117246174"
          ],
          "P1056": {
            "id": "Q117217619",
            "label": "AI prompt"
          },
          "P5008": "Q117245199",
          "practiced_by": [
            "Q117674392",
            "Q123653520"
          ],
          "commons_category": "Prompt engineering for generative AI",
          "google_kg_id": "/g/11p6kpgt_n",
          "P691": "ph1266210"
        }
      }
    },
    {
      "name": "Zero-shot learning",
      "entity_type": "concept",
      "relation": "proposes",
      "relevance": "The paper proposes zero-shot TTS that can synthesize speech for unseen speakers with minimal enrollment data.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Zero-shot_learning",
      "wikidata": {
        "id": "Q96416030",
        "label": "zero-shot learning",
        "description": "problem setup in machine learning, where at test time, a learner observes samples from classes that were not observed during training, and needs to predict the class they belong to",
        "aliases": [
          "Zero-shot learning",
          "ZSL"
        ],
        "claims": {
          "google_kg_id": "/g/11jfgvngpm",
          "subclass_of": "Q2539",
          "P138": {
            "id": "Q7092335",
            "label": "one-shot learning"
          },
          "P9100": "zero-shot-learning",
          "instance_of": [
            {
              "id": "Q1047113",
              "label": "field of study"
            },
            "Q2267705"
          ],
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Audio codec",
      "entity_type": "tool",
      "relation": "uses",
      "relevance": "Vall-E uses discrete codes derived from an off-the-shelf neural audio codec model.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Audio_codec",
      "wikidata": {
        "id": "Q2481505",
        "label": "audio codec",
        "description": "device or program that encodes/decodes audio data in some bitstream format",
        "aliases": [],
        "claims": {
          "subclass_of": {
            "id": "Q184748",
            "label": "codec"
          },
          "topic_main_category": "Q8275524",
          "freebase_id": "/m/0f731",
          "commons_category": "Audio codecs",
          "P2888": "http://cv.iptc.org/newscodes/audiocodec/",
          "instance_of": "Q17155032",
          "P5429": "audiocodec",
          "P989": "En-Audio codec-article.ogg",
          "mag_id": "2776153946",
          "P4428": "Q758871",
          "different_from": "Q758871"
        }
      }
    },
    {
      "name": "Speaker recognition",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "The paper uses speaker embedding concepts from speaker recognition to achieve speaker similarity in synthesis.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Speaker_recognition",
      "wikidata": {
        "id": "Q1145189",
        "label": "speaker recognition",
        "description": "identification of a person from characteristics of voices",
        "aliases": [
          "voice recognition"
        ],
        "claims": {
          "topic_main_category": {
            "id": "Q8789025",
            "label": "Category:Speaker recognition"
          },
          "freebase_id": "/m/03_zq7",
          "quora_topic_id": "Speaker-Recognition",
          "P3827": "voice-control",
          "subclass_of": "Q21142755",
          "loc_id": "sh85144234",
          "mag_id": "133892786",
          "P8189": "987007543990405171",
          "openalex_id": [
            "C133892786",
            "C2982762665",
            "C2986627078"
          ],
          "P2347": "8267",
          "openalex_topic_id": [
            "204042",
            "121713"
          ],
          "P691": "ph1090096",
          "mesh_id": "D000087024",
          "mesh_tree_code": [
            "F02.463.593.071.937.500",
            "F02.463.593.524.250.750",
            "G07.888.125.937.500"
          ],
          "P2892": "C0920674",
          "P1617": "42882590-2855-4dcf-9305-6a98154068f0",
          "P1535": [
            {
              "id": "Q806718",
              "label": "economics of banking"
            },
            "Q26884850",
            {
              "id": "Q3467906",
              "label": "virtual assistant"
            },
            "Q11190",
            "Q1494322",
            {
              "id": "Q123582052",
              "label": "biometric authentication"
            }
          ],
          "P13397": "speaker-recognition",
          "P13591": "concept/42a562e8-eda8-4489-af60-0912f643141b"
        }
      }
    },
    {
      "name": "Deep learning speech synthesis",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "Vall-E builds on deep learning approaches to speech synthesis by introducing a language modeling perspective.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Deep_learning_speech_synthesis",
      "wikidata": {
        "id": "Q109973683",
        "label": "Deep learning speech synthesis",
        "description": "method of speech synthesis that uses deep neural networks",
        "aliases": [],
        "claims": {
          "instance_of": [
            {
              "id": "Q197536",
              "label": "deep learning"
            },
            "Q52946",
            {
              "id": "Q16346",
              "label": "speech synthesis"
            }
          ]
        }
      }
    }
  ]
}