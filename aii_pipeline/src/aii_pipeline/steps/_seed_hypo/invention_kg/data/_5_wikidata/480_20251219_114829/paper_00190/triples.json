{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Reinforcement learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "The paper applies reinforcement learning as the core technique for training sub-policies.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": "Q2539",
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": "Q2539",
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            {
              "id": "Q111862379",
              "label": "machine learning method"
            },
            {
              "id": "Q130609847",
              "label": "learning approach"
            }
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    },
    {
      "name": "Actor-critic algorithm",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "SAC (Soft Actor-Critic) is an actor-critic algorithm used to train the six sub-policies.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Actor-critic_algorithm",
      "wikidata": {
        "id": "Q131936605",
        "label": "Actor-critic algorithm",
        "description": "reinforcement learning algorithms that combine policy and value estimation",
        "aliases": [],
        "claims": {
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Supervised learning",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "A supervised high-level stage selector is trained to coordinate between the six sub-policies.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Supervised_learning",
      "wikidata": {
        "id": "Q334384",
        "label": "supervised learning",
        "description": "machine learning task of learning a function that maps an input to an output based on example input-output pairs",
        "aliases": [
          "supervised machine learning"
        ],
        "claims": {
          "freebase_id": "/m/0586t",
          "part_of": "Q2539",
          "instance_of": {
            "id": "Q1047113",
            "label": "field of study"
          },
          "subclass_of": [
            "Q2539",
            {
              "id": "Q111862379",
              "label": "machine learning method"
            }
          ],
          "opposite_of": "Q1152135",
          "mesh_id": "D000069553",
          "quora_topic_id": "Supervised-Learning",
          "babelnet_id": "01366724n",
          "P2179": "10010259",
          "loc_id": "sh94008290",
          "P1245": "1706209",
          "mag_id": "136389625",
          "P9100": "supervised-learning",
          "P9982": "28740",
          "P8189": "987007561023305171",
          "P1535": {
            "id": "Q29169143",
            "label": "data scientist"
          },
          "P2579": "Q2539",
          "openalex_id": "C136389625",
          "openalex_topic_id": [
            "204028",
            "216638"
          ],
          "P7502": "Supervised_Learning-6AM",
          "uses": {
            "id": "Q5282087",
            "label": "discriminative model"
          },
          "topic_main_category": "Q30640394",
          "mesh_tree_code": [
            "G17.035.250.500.500",
            "L01.224.050.375.530.500"
          ],
          "P1149": "Q325.75",
          "P11662": "3582082",
          "P3235": "supervised-learning",
          "P13591": "concept/cf583102-236b-4653-a870-fc87150b4484",
          "P508": "79136"
        }
      }
    },
    {
      "name": "Robot learning",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Robot learning techniques enable the Panda arm to acquire manipulation skills through learning algorithms.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Robot_learning",
      "wikidata": {
        "id": "Q7353390",
        "label": "robot learning",
        "description": "machine learning for robots",
        "aliases": [],
        "claims": {
          "mag_id": "188888258",
          "freebase_id": "/m/093nl0",
          "openalex_id": "C188888258",
          "P1269": "Q170978",
          "subclass_of": "Q2539",
          "P13397": "robot-learning"
        }
      }
    },
    {
      "name": "Robotic arm",
      "entity_type": "tool",
      "relation": "uses",
      "relevance": "The Franka Emika Panda is a robotic arm used as the physical platform for manipulation tasks.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Robotic_arm",
      "wikidata": {
        "id": "Q40687",
        "label": "robotic arm",
        "description": "type of mechanical arm with similar functions to a human arm",
        "aliases": [
          "robot arm"
        ],
        "claims": {
          "commons_category": "Handling robots",
          "freebase_id": "/m/02qf6jc",
          "subclass_of": [
            {
              "id": "Q11012",
              "label": "robot"
            },
            "Q30587750"
          ],
          "quora_topic_id": "Robotic-Arm",
          "part_of": {
            "id": "Q11012",
            "label": "robot"
          },
          "mag_id": "150415221",
          "stack_exchange_tag": "https://robotics.stackexchange.com/tags/robotic-arm",
          "P8408": "RoboticArm",
          "image": [
            "Blueblack preview featured.jpg",
            "STS-114 Steve Robinson on Canadarm2.jpg"
          ],
          "P3451": "HTV-6 final approach towards the International Space Station (3).jpg",
          "openalex_id": [
            "C150415221",
            "C2988191880",
            "C2987841220"
          ],
          "P13397": "robotic-arm"
        }
      }
    },
    {
      "name": "Grasp",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "Grasp-constrained manipulation requires understanding grasping mechanics and constraints on object interaction.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Grasp",
      "wikidata": {
        "id": "Q5597405",
        "label": "grasping",
        "description": "act of taking, holding or seizing firmly with (or as if with) the hand",
        "aliases": [
          "gripping",
          "grasp",
          "grip",
          "grab"
        ],
        "claims": {
          "instance_of": {
            "id": "Q846785",
            "label": "action"
          },
          "freebase_id": "/m/0k2fv6h",
          "P1542": "Q108951109",
          "subclass_of": "Q38183514",
          "uses": "Q110558047",
          "opposite_of": "Q110560444",
          "different_from": "Q108951109",
          "commons_category": "Grasping",
          "P11473": "1749",
          "P12913": {
            "id": "Q33767",
            "label": "hand"
          },
          "image": "Protect your hands! LCCN98518513.jpg",
          "P828": {
            "id": "Q1587588",
            "label": "manipulator"
          }
        }
      }
    },
    {
      "name": "Multi-stage learning approach",
      "entity_type": "method",
      "relation": "proposes",
      "relevance": "The paper proposes a novel decomposition of manipulation tasks into six independently trained sub-policies with a high-level stage selector.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "wikidata": {
        "id": "Q830687",
        "label": "reinforcement learning",
        "description": "type of machine learning where an agent learns how to behave in an environment by performing actions and receiving rewards or penalties in return, aiming to maximize the cumulative reward over time",
        "aliases": [
          "RL"
        ],
        "claims": {
          "freebase_id": "/m/0hjlw",
          "stack_exchange_tag": [
            "https://stackoverflow.com/tags/reinforcement-learning",
            "https://ai.stackexchange.com/tags/reinforcement-learning"
          ],
          "part_of": "Q2539",
          "quora_topic_id": "Reinforcement-Learning",
          "subclass_of": "Q2539",
          "babelnet_id": "03511335n",
          "P2179": "10010261",
          "mag_id": "97541855",
          "P7502": [
            "Reinforcement_Learning-R39",
            "Reinforcement_Learning"
          ],
          "P9100": "reinforcement-learning",
          "P9526": "Reinforcement_learning",
          "P508": "69813",
          "P268": "17127232k",
          "loc_id": "sh92000704",
          "gnd_id": "4825546-4",
          "P8189": "987007546785305171",
          "P8529": "461105",
          "openalex_id": "C97541855",
          "P10": "A-novel-approach-to-locomotion-learning-Actor-Critic-architecture-using-central-pattern-generators-Movie1.ogv",
          "openalex_topic_id": [
            "216762",
            "121743",
            "504466"
          ],
          "commons_category": "Reinforcement learning",
          "P6009": "32055",
          "P3984": "reinforcementlearning",
          "instance_of": [
            {
              "id": "Q111862379",
              "label": "machine learning method"
            },
            {
              "id": "Q130609847",
              "label": "learning approach"
            }
          ],
          "P8687": "+30816",
          "P10376": [
            "computer-science/reinforcement-learning",
            "neuroscience/reinforcement-learning"
          ],
          "topic_main_category": "Q87071489",
          "P8885": "강화학습",
          "P1149": "Q325.6",
          "mesh_id": "D000098408",
          "mesh_tree_code": [
            "G17.035.250.500.485",
            "L01.224.050.375.530.485"
          ],
          "described_by_source": "Q133280541",
          "different_from": {
            "id": "Q123916004",
            "label": "inverse reinforcement learning"
          },
          "P3235": "reinforcement-learning",
          "P13591": "concept/62f2752a-56e6-44ef-ac2f-b8bb40173d38",
          "P1036": "006.31"
        }
      }
    }
  ]
}