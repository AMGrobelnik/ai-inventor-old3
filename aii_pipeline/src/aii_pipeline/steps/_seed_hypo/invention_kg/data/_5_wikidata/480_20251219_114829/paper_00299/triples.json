{
  "paper_type": "contribution",
  "triples": [
    {
      "name": "Language model",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "LaMDA is built on the language model architecture and pre-training paradigm.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Language_model",
      "wikidata": {
        "id": "Q3621696",
        "label": "language model",
        "description": "probabilistic model of a natural or formal language, or generally of elements of signal sequences",
        "aliases": [],
        "claims": {
          "freebase_id": "/m/065lv0",
          "mag_id": "137293760",
          "subclass_of": "Q3284399",
          "P1269": {
            "id": "Q30642",
            "label": "natural language processing"
          },
          "P8408": "LanguageModeling",
          "openalex_id": "C137293760",
          "P10407": "923-2",
          "use": "Q96407327",
          "openalex_topic_id": "184201",
          "topic_main_category": "Q16500316",
          "P12086": "Taalmodel",
          "P8309": "18-332728",
          "P1368": "000355288",
          "P13397": "language+model",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Dialogue system",
      "entity_type": "task",
      "relation": "uses",
      "relevance": "LaMDA is specifically designed to handle dialogue applications.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Dialogue_system",
      "wikidata": {
        "id": "Q5270587",
        "label": "dialogue system",
        "description": "computer system intended to converse with a human",
        "aliases": [
          "dialog system",
          "conversational agent",
          "man-machine conversation"
        ],
        "claims": {
          "subclass_of": [
            "Q121182",
            {
              "id": "Q30642",
              "label": "natural language processing"
            }
          ],
          "mag_id": "190954187",
          "freebase_id": "/m/08y96v",
          "openalex_id": "C190954187",
          "P691": "ph351273",
          "google_kg_id": "/g/121hrdl8"
        }
      }
    },
    {
      "name": "Transformer (deep learning)",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "LaMDA uses Transformer-based neural network architecture as its foundation.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
      "wikidata": {
        "id": "Q85810444",
        "label": "transformer",
        "description": "machine-learning model architecture first developed by Google Brain",
        "aliases": [
          "transformer model",
          "transformer architecture",
          "transformers"
        ],
        "claims": {
          "subclass_of": [
            "Q192776",
            {
              "id": "Q113364611",
              "label": "deep learning model"
            }
          ],
          "developer": [
            {
              "id": "Q16927616",
              "label": "Google Brain"
            },
            {
              "id": "Q44749723",
              "label": "Ashish Vaswani"
            },
            "Q30251943"
          ],
          "follows": [
            {
              "id": "Q1457734",
              "label": "recurrent neural network"
            },
            {
              "id": "Q6673524",
              "label": "long short-term memory"
            }
          ],
          "described_by_source": {
            "id": "Q30249683",
            "label": "Attention Is All You Need"
          },
          "google_kg_id": "/g/11hz_m4ssw",
          "has_parts": [
            "Q42586063",
            {
              "id": "Q745243",
              "label": "decoder"
            }
          ],
          "uses": [
            {
              "id": "Q103701642",
              "label": "attention"
            },
            {
              "id": "Q5441227",
              "label": "feedforward neural network"
            }
          ],
          "use": [
            {
              "id": "Q30642",
              "label": "natural language processing"
            },
            {
              "id": "Q844240",
              "label": "computer vision"
            },
            {
              "id": "Q3245113",
              "label": "statistical machine translation"
            },
            {
              "id": "Q1394144",
              "label": "automatic summarization"
            }
          ],
          "schematic": "Transformer, full architecture.png",
          "stack_exchange_tag": "https://ai.stackexchange.com/tags/transformer",
          "P575": "2017-06-12",
          "P3342": {
            "id": "Q97454550",
            "label": "Michal Valko"
          }
        }
      }
    },
    {
      "name": "Fine-tuning (deep learning)",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "The paper demonstrates fine-tuning with annotated data to improve safety and factual grounding.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)",
      "wikidata": {
        "id": "Q117286419",
        "label": "fine-tuning",
        "description": "process of taking a pre-trained model and further training it on a smaller, specific dataset to adapt or improve its performance for a particular task or domain",
        "aliases": [
          "neural network fine-tuning"
        ],
        "claims": {
          "instance_of": "Q117348143",
          "commons_category": "AI model fine-tuning",
          "follows": {
            "id": "Q124149651",
            "label": "pre-training"
          },
          "subclass_of": "Q1714153",
          "P10": "Easiest Way to Build Consistent Character - Step-by-Step Guide with OpenArt.webm"
        }
      }
    },
    {
      "name": "Information retrieval",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "LaMDA consults information retrieval systems as one of its external knowledge sources.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Information_retrieval",
      "wikidata": {
        "id": "Q816826",
        "label": "information retrieval",
        "description": "activity of obtaining information resources relevant to an information need from a collection of information resources",
        "aliases": [
          "IR",
          "information storage and retrieval",
          "info retrieval",
          "Information retrieval"
        ],
        "claims": {
          "P508": "46118",
          "topic_main_category": "Q8548779",
          "P349": "00575010",
          "freebase_id": "/m/03y9s",
          "stack_exchange_tag": "https://stackoverflow.com/tags/information-retrieval",
          "commons_category": "Information retrieval",
          "subclass_of": [
            {
              "id": "Q11540953",
              "label": "search"
            },
            {
              "id": "Q110458263",
              "label": "taking"
            }
          ],
          "quora_topic_id": "Information-Retrieval",
          "P3827": [
            "information-storage-and-retrieval-systems",
            "information-retrieval"
          ],
          "gnd_id": "4072803-1",
          "P3916": "concept514",
          "instance_of": [
            {
              "id": "Q1914636",
              "label": "activity"
            },
            {
              "id": "Q1047113",
              "label": "field of study"
            },
            "Q2267705",
            "Q125186879"
          ],
          "babelnet_id": "00744700n",
          "loc_id": "sh85066148",
          "P5398": "000001825",
          "P1014": "300155377",
          "P443": "LL-Q150 (fra)-0x010C-recherche d'information.wav",
          "P1051": "6504",
          "mesh_id": "D016247",
          "mesh_tree_code": [
            "L01.313.500.750.280",
            "L01.470"
          ],
          "P7033": "scot/9261",
          "P268": "122132635",
          "P5801": "Information_Retrieval",
          "P1245": "986741",
          "britannica_id": "topic/information-retrieval",
          "mag_id": [
            "23123220",
            "2776561884"
          ],
          "P2347": "2964",
          "P2579": "Q21198",
          "P8408": "InformationRetrieval",
          "P8519": "81631",
          "P4342": "informasjonsgjenfinning",
          "P4527": "91664",
          "different_from": [
            {
              "id": "Q18733",
              "label": "recall"
            },
            "Q1638872"
          ],
          "P950": "XX535604",
          "P9100": "information-retrieval",
          "P2924": "3151044",
          "P2004": "47256",
          "openalex_id": "C23123220",
          "P8313": "informationssøgning",
          "P691": "ph163856",
          "P10784": "ir",
          "P8189": "987007550614905171",
          "P7502": "Information_retrieval-8B96",
          "P11567": [
            "information-retrieval",
            "retrieval"
          ],
          "P11662": "786971",
          "P9497": "249",
          "P7870": "58321",
          "P2892": "C3661499",
          "P9309": "informationRetrieval",
          "short_name": "IR",
          "openalex_topic_id": "133879",
          "P5437": "156",
          "P13411": {
            "id": "Q1828",
            "label": "Tonndorf"
          },
          "P13591": "concept/826cbdab-3491-4167-834f-9590f0873174",
          "P1036": [
            "025.04",
            "025.524",
            "005.74"
          ],
          "P12913": {
            "id": "Q11028",
            "label": "information"
          }
        }
      }
    },
    {
      "name": "Machine translation",
      "entity_type": "tool",
      "relation": "uses",
      "relevance": "LaMDA uses language translators as external knowledge sources for grounding responses.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Machine_translation",
      "wikidata": {
        "id": "Q79798",
        "label": "machine translation",
        "description": "use of software for language translation",
        "aliases": [
          "MT",
          "automatic translation"
        ],
        "claims": {
          "P508": "9915",
          "topic_main_category": {
            "id": "Q7015863",
            "label": "Category:Machine translation"
          },
          "P349": "00565743",
          "freebase_id": "/m/050ls",
          "P1051": "6683",
          "commons_category": "Machine translation",
          "subclass_of": [
            {
              "id": "Q7553",
              "label": "translation"
            },
            "Q182557",
            {
              "id": "Q30642",
              "label": "natural language processing"
            }
          ],
          "quora_topic_id": "Machine-Translation",
          "P3827": "machine-translation",
          "topic_maintained_by": [
            "Q6681991",
            {
              "id": "Q25989935",
              "label": "Template:Machine translation"
            }
          ],
          "gnd_id": "4003966-3",
          "P2924": "1799594",
          "P5398": "000000133",
          "P2579": {
            "id": "Q30642",
            "label": "natural language processing"
          },
          "britannica_id": "topic/machine-translation",
          "loc_id": "sh00006582",
          "P443": [
            "LL-Q8752 (eus)-ElsaBornFree-Itzulpengintza automatiko.wav",
            "De-maschinelle Übersetzung.ogg"
          ],
          "mag_id": "203005215",
          "stack_exchange_tag": [
            "https://ai.stackexchange.com/tags/machine-translation",
            "https://linguistics.stackexchange.com/tags/machine-translation",
            "https://datascience.stackexchange.com/tags/machine-translation",
            "https://stackoverflow.com/tags/machine-translation"
          ],
          "P2184": {
            "id": "Q3231826",
            "label": "history of machine translation"
          },
          "P6900": "機械翻訳",
          "P8408": "MachineTranslation",
          "short_name": "MT",
          "P5337": "CAAqJQgKIh9DQkFTRVFvSUwyMHZNRFV3YkhNU0JXVnVMVWRDS0FBUAE",
          "P268": "11947452q",
          "P2347": "39319",
          "P3553": "19616892",
          "image": "Word Lens Demo 23Dec2010.png",
          "P9100": "machine-translation",
          "described_by_source": {
            "id": "Q108928644",
            "label": "Open Science Thesaurus"
          },
          "openalex_id": [
            "C203005215",
            "C2992676002",
            "C2986258472"
          ],
          "P6385": "gumanitarnye_nauki/lingvistika/MASHINNI_PEREVOD.html",
          "P8313": "maskinoversættelse",
          "P691": "ph436036",
          "P6870": "93661",
          "P11012": {
            "id": "Q4287591",
            "label": "Scoterpes copei"
          },
          "P1535": {
            "id": "Q28031555",
            "label": "machine translation software"
          },
          "P1368": "000140131",
          "P3916": "concept3410",
          "openalex_topic_id": [
            "216642",
            "26833"
          ],
          "P10376": [
            "computer-science/machine-translation",
            "physics-and-astronomy/machine-translation",
            "earth-and-planetary-sciences/machine-translation"
          ],
          "P9621": "traduzione-automatica",
          "P9775": "traduzione-automatica",
          "P1617": "615ab399-0fe4-485b-aa32-c62b0b806fc6",
          "P8189": "987007292868605171",
          "P5437": "5200",
          "P5587": "hftwvpn13p4m2xd",
          "P1036": [
            "418.020285635",
            "006.454"
          ],
          "P11408": "機械翻訳",
          "P13411": "Q166",
          "P4644": "32a2c63d-2d13-4784-abb8-678ef2cd8a46",
          "schematic": [
            "Direct translation and transfer translation pyramid.svg",
            "Direct translation and transfer translation pyramind.vi.svg",
            "Direct translation and transfer translation pyramind mk.svg"
          ],
          "P13591": "concept/207ff001-ea57-4b0b-9579-de59016dfbe9",
          "P13691": "29826"
        }
      }
    },
    {
      "name": "Crowdsourcing",
      "entity_type": "method",
      "relation": "uses",
      "relevance": "LaMDA uses crowdworker-annotated data to fine-tune safety classifiers.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Crowdsourcing",
      "wikidata": {
        "id": "Q275969",
        "label": "crowdsourcing",
        "description": "obtaining services, ideas, or content from a group of people, rather than from employees or suppliers",
        "aliases": [
          "Crowd sourcing",
          "Crowd-Sourcing",
          "Crowdworking"
        ],
        "claims": {
          "commons_category": "Crowdsourcing",
          "subclass_of": {
            "id": "Q1056396",
            "label": "human resource management"
          },
          "topic_main_category": "Q6344840",
          "freebase_id": "/m/0dcz_v",
          "image": "Kulturminister Uffe Elbæk taster (8166806679).jpg",
          "quora_topic_id": "Crowdsourcing",
          "P508": "53058",
          "P3827": "crowdsourcing",
          "mesh_id": "D063045",
          "mesh_tree_code": "L01.399.250.179",
          "P1245": "1629310",
          "mag_id": "62230096",
          "P2347": "25552",
          "P1368": "000300427",
          "P9272": "55135",
          "P3553": "19556406",
          "loc_id": "sh2017004056",
          "P3984": "Crowdsourcing",
          "P9100": "crowdsourcing",
          "P2179": "10003296",
          "openalex_id": [
            "C3018396927",
            "C62230096"
          ],
          "P4342": "crowdsourcing",
          "openalex_topic_id": "218570",
          "P11137": "crowdsourcing",
          "P3911": "29770-6",
          "P11567": "crowdsourcing",
          "P7870": "52366",
          "described_by_source": "Q120799836",
          "P9309": "crowdsourcing",
          "P2579": {
            "id": "Q124628194",
            "label": "crowdsourced science"
          },
          "P3222": "crowdsourcing",
          "P13591": "concept/7870f66f-fbd0-42e3-87a1-b244b4878988"
        }
      }
    },
    {
      "name": "Algorithmic bias",
      "entity_type": "concept",
      "relation": "uses",
      "relevance": "The paper addresses unfair bias as a key safety challenge for dialogue models.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Algorithmic_bias",
      "wikidata": {
        "id": "Q45253460",
        "label": "algorithmic bias",
        "description": "systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one arbitrary group of users over others",
        "aliases": [
          "technical bias"
        ],
        "claims": {
          "subclass_of": {
            "id": "Q742736",
            "label": "bias"
          },
          "google_kg_id": "/g/11h9q1rwmd",
          "instance_of": [
            "Q29485",
            {
              "id": "Q6108858",
              "label": "technology risk"
            },
            {
              "id": "Q100912473",
              "label": "type of bias"
            }
          ]
        }
      }
    },
    {
      "name": "Knowledge graph",
      "entity_type": "artifact",
      "relation": "uses",
      "relevance": "Knowledge sources and external information structures support factual grounding in LaMDA.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/Knowledge_graph",
      "wikidata": {
        "id": "Q33002955",
        "label": "knowledge graph",
        "description": "information repository structured as a graph",
        "aliases": [
          "concept of knowledge graph",
          "knowledge graphs"
        ],
        "claims": {
          "subclass_of": [
            "Q115636432",
            {
              "id": "Q593744",
              "label": "knowledge base"
            }
          ],
          "image": "Wikidata knowledge graph - Christine Choy.png",
          "different_from": [
            "Q65047047",
            {
              "id": "Q648625",
              "label": "Google Knowledge Graph"
            }
          ],
          "P2579": [
            {
              "id": "Q1027508",
              "label": "ontology engineering"
            },
            "Q21198"
          ],
          "P8408": "KnowledgeGraph",
          "topic_main_category": {
            "id": "Q105109925",
            "label": "Category:Knowledge graphs"
          },
          "P9100": "knowledge-graph",
          "google_kg_id": "/g/11jtypdlnf",
          "P571": "1972-00-00",
          "openalex_id": "C2987255567",
          "openalex_topic_id": [
            "217113",
            "236203",
            "170362",
            "628814",
            "549350"
          ],
          "uses": "Q324254",
          "P973": [
            "https://enterprise-knowledge.com/whats-the-difference-between-an-ontology-and-a-knowledge-graph/",
            "https://www.ibm.com/de-de/topics/knowledge-graph",
            "https://www.fiz-karlsruhe.de/de/nachricht/wissensgraphen-ihre-bedeutung-der-digitalen-welt-von-heute"
          ],
          "commons_category": "Knowledge graphs",
          "P10376": "social-sciences/knowledge-graph",
          "P691": "ph1197788",
          "P8168": "Q550371",
          "P9885": "7fedec32-ded0-fa4b-3951-a9e2afaf55d5",
          "P7783": "202106000793662230"
        }
      }
    },
    {
      "name": "LaMDA",
      "entity_type": "artifact",
      "relation": "proposes",
      "relevance": "LaMDA is the novel family of dialogue-specialized language models proposed and evaluated in the paper.",
      "wikipedia_url": "https://en.wikipedia.org/wiki/LaMDA",
      "wikidata": {
        "id": "Q112624345",
        "label": "LaMDA",
        "description": "family of large language models",
        "aliases": [
          "Language Model for Dialog Applications",
          "Language Model for Dialogue Applications",
          "Meena"
        ],
        "claims": {
          "developer": {
            "id": "Q95",
            "label": "Google"
          },
          "instance_of": "Q124629760",
          "described_by_source": "Q113570813",
          "P973": "https://www.noemamag.com/ai-and-the-limits-of-language/",
          "P577": "2020-00-00",
          "P571": "2020-00-00",
          "P1476": "LaMDA",
          "different_from": {
            "id": "Q116894231",
            "label": "LLaMA"
          }
        }
      }
    }
  ]
}